{"./":{"url":"./","title":"首页","keywords":"","body":"YZJ's Blog 个人博客 Author: yangzejin Email: i@yangzejin.com 免费的GPT3：gpt.yangzejin.com Copyright © YZJ 2022 all right reserved，powered by Gitbook更新时间： 2023-08-13 14:53:25 "},"C++.html":{"url":"C++.html","title":"C++","keywords":"","body":"C++ 基础 C语言和C++的区别以及C++特点 C语言是C++的子集，C++可以很好兼容C语言。但是C++11又有很多新特性引入了nullptr、auto变量、Lambda匿名函数、右值引用、智能指针。 C++是面向对象的编程语言，C++引入了新的数据类型 类，由此引申出了三大特性：封装、继承、多态。而C语言则是面向过程的编程语言。 C语言有一些不安全的语言特性，如指针使用的潜在危险、强制转换的不确定性、内存泄露等。而C++对此增加了不少新特性来改善安全性，如const常量、引用、四类cast转换（static_cast、dynamic_cast、const_cast、reinterpret_cast）、智能指针、try—catch等等； C++可复用性高，C++引入了模板的概念，后面在此基础上，实现了方便开发的标准模板库STL（Standard Template Library）。STL的一个重要特点是数据结构和算法的分离，其体现了泛型化程序设计的思想。C++的STL库相对于C语言的函数库更灵活、更通用。 C++语言编写出的程序结构清晰、易于扩充，程序可读性好 C++生成的代码质量高，运行效率高，仅比汇编语言慢10%～20%； include头文件双引号\"\"和尖括号<>的区别？ 区别： 尖括号<>的头文件是系统文件，双引号\"\"的头文件是自定义文件，编译器预处理阶段查找头文件的路径不一样。 查找路径： <>的头文件：编译器设置的头文件路径-->系统变量。 \"\"的头文件：默认从项目当前目录查找头文件。 动态链接与静态链接区别？ 静态链接，是在链接的时候就已经把要调用的函数或者过程链接到了生成的可执行文件中，就算你在去把静态库删除也不会影响可执行程序的执行；生成的静态链接库，Windows下以.lib为后缀，Linux下以.a为后缀。 动态链接，是在链接的时候没有把调用的函数代码链接进去，而是在执行的过程中，再去找要链接的函数，生成的可执行文件中没有函数代码，只包含函数的重定位信息，所以当你删除动态库时，可执行程序就不能运行。生成的动态链接库，Windows下以.dll为后缀，Linux下以.so为后缀。 区别 静态链接是将各个模块的obj和库链接成一个完整的可执行程序；而动态链接是程序在运行的时候寻找动态库的函数符号（重定位） 静态链接运行快、可独立运行；动态链接运行较慢(事实上，动态库被广泛使用，这个缺点可以忽略)、不可独立运行。 静态链接浪费空间，存在多个副本，同一个函数的多次调用会被多次链接进可执行程序，当库和模块修改时，main也需要重编译；动态链接节省空间，相同的函数只有一份，当库和模块修改时，main不需要重编译。 静态类型/动态类型和静态绑定/动态绑定 静态类型：对象在声明时采用的类型，在编译期既已确定； 动态类型：通常是指一个指针或引用目前所指对象的类型，是在运行期决定的； 静态绑定：绑定的是静态类型，所对应的函数或属性依赖于对象的静态类型，发生在编译期； 动态绑定：绑定的是动态类型，所对应的函数或属性依赖于对象的动态类型，发生在运行期； 从上面的定义也可以看出，非虚函数一般都是静态绑定，而虚函数都是动态绑定（如此才可实现多态性）。 代码到可执行文件过程？ gcc是GNU编译器合集，能编译C, C++, Objective-C, Objective-C++, Fortran, Ada, D, Go, and BRIG (HSAIL)多种语言，g++能编译 c & c++ 使用g++ test.cpp -o test或g++ test.cpp 会自动执行上述流程 g++ -std=c++11 a.cpp 支持c++11编译 option 功能 举例 输出格式 -E 预处理 宏替换、头文件展开、去掉注释g++ -E test.cpp -o test.i *.i -S 生成汇编文件 g++ -S test.i -o test.s *. s -c 生成二进制文件,可被直接执行 g++ -c test.s -o test.o *. o -o 生成最终可执行文件 g++ test.o -o test *.out(默认) -I参数是用来指定头文件所在目录 原码、反码、补码？ 整型数值在计算机的存储里，最左边的一位代表符号位，0代表正数，1代表负数。 原码：为二进制的数，如：10 原码为0000 1010 反码：正数的反码与原码相同：如：10 原码为0000 1010，反码为0000 1010 负数为原码0变1，1变0，（符号位不变）：如：-10 原码为1000 1010，反码为1111 0101 补码：正数的补码与原码相同：如：10 原码为0000 1010，补码为0000 1010 负数的补码为反码加1：如：-10 反码为1111 0101，补码为1111 0110 正数：原码=反码=补码 负数：原码=反码（原码取反）=补码（反码＋1） 大端 小端？ 大端存储：字数据的高字节存储在低地址中 小端存储：字数据的低字节存储在低地址中 在Socket编程中，往往需要将操作系统所用的小端存储的IP地址转换为大端存储，这样才能进行网络传输 #include using namespace std; int main() { int a = 0x1234; //由于int和char的长度不同，借助int型转换成char型，只会留下低地址的部分 char c = (char)(a); if (c == 0x12) cout 结构体和共用体的区别？ struct和union都是由多个不同的数据类型成员组成。 struct的所有成员都存在；但在任何同一时刻, union中只存放了一个被选中的成员，共用体是共用内存空间，所以每个成员都是读写同一个内存空间，那么内存空间里面的内容不停的被覆盖，而同一时刻，都只能操作一个成员变量。否则会出现读错误。 在不考虑字节对齐的情况下，struct变量的总长度等于所有成员长度之和。Union变量的长度等于最长的成员的长度。 struct的不同成员赋值是互不影响的；而对于union的不同成员赋值, 将会对其它成员重写, 原来成员的值就不存在了。 枚举 enum是一个派生数据类型，它可以声明、定义一个整型常数集合（默认从0开始顺序定义）。所不同的是，集合里面的整型常数是用其他名字代替的，但只是代替，其本质还是一个整型常数。（让外界可以通过名字知道这些常数的含义，常用于定义状态码） C++中 struct 和 class 的区别？ struct 一般用于描述一个数据结构集合，而 class 是对一个对象数据的封装； struct 中默认的访问控制权限是 public 的，而 class 中默认的访问控制权限是 private 的，例如： struct A{ int iNum; // 默认访问控制权限是 public } class B{ int iNum; // 默认访问控制权限是 private } 在继承关系中，struct 默认是公有继承，而 class 是私有继承； class 关键字可以用于定义模板参数，就像 typename，而 struct 不能用于定义模板参数，例如： template // 可以把typename 换成 class int Func(const T& t, const Y& y) { //TODO } C++结构体和C结构体的区别？ （1）C的结构体内不允许有函数存在，C++允许有内部成员函数，且允许该函数是虚函数。 （2）C的结构体对内部成员变量的访问权限只能是public，而C++允许public,protected,private三种。 （3）C语言的结构体是不可以继承的，C++的结构体是可以从其他的结构体或者类继承过来的。 （4）C 中使用结构体需要加上 struct 关键字，或者对结构体使用 typedef 取别名，而 C++ 中可以省略 struct 关键字直接使用。 C++有几种传值方式，区别是什么？ 值传递：形参即使在函数体内值发生变化，也不会影响实参的值；在函数传参的过程中，函数会为形参申请新的内存空间，并将实参的值复制给形参。形参的改变当然不会影响实参的值。 引用传递：形参在函数体内值发生变化，会影响实参的值； 指针传递：在指针指向没有发生改变的前提下，形参在函数体内值发生变化，会影响实参的值； 全局变量和局部变量的区别？ 作用域不同：全局变量的作用域为整个程序，而局部变量的作用域为当前函数或循环等 内存存储方式不同：全局变量存储在全局数据区中，局部变量存储在栈区 生命期不同：全局变量的生命期和主程序一样，随程序的销毁而销毁，局部变量在函数内部或循环内部，随函数的退出或循环退出就不存在了 使用方式不同：全局变量在声明后程序的各个部分都可以用到，但是局部变量只能在局部使用。函数内部会优先使用局部变量再使用全局变量。 当局部变量被定义时，系统不会对其初始化，必须自行对其初始化。定义全局变量时，系统会自动初始化为下列值： 数据类型 初始化默认值 int 0 char '\\0' float 0 double 0 pointer NULL C++内存分布模型 如上图，从低地址到高地址，一个程序由代码段、数据段、BSS段、堆栈段组成。 代码段：存放程序执行代码的一块内存区域。只读，不允许修改，代码段的头部还会包含一些只读的常量，如字符串常量字面值（注意：const变量虽然属于常量，但是本质还是变量，不存储于代码段）。 数据段data：存放程序中已初始化的非零全局变量和静态变量的一块内存区域。 BSS 段：存放程序中未初始化的全局变量和静态变量的一块内存区域。 可执行程序在运行时又会多出两个区域：堆区和栈区。 堆区：动态申请内存用。堆从低地址向高地址增长。 栈区：存储局部变量、函数参数值。栈从高地址向低地址增长。是一块连续的空间。 最后还有一个文件映射区（共享区），位于堆和栈之间。 初始化为0的全局变量在bss还是data？ BSS段通常是指用来存放程序中未初始化的或者初始化为0的全局变量和静态变量的一块内存区域。特点是可读写的，在程序执行之前BSS段会自动清0。 堆和栈的区别？ 堆栈空间分配不同。栈由操作系统自动分配释放 ，存放函数的参数值，局部变量的值等，栈有着很高的效率；堆一般由程序员分配释放，堆的效率比栈要低的多。 堆栈缓存方式不同。栈使用的是一级缓存， 它们通常都是被调用时处于存储空间中，调用完毕立即释放；堆则是存放在二级缓存中，速度要慢些。 空间大小： 栈的空间大小并不大，一般最多为2M，超过之后会报Overflow错误。堆的空间非常大，理论上可以接近3G。（针对32位程序来说，可以看到内存分布，1G用于内核空间，用户空间中栈、BSS、data又要占一部分，所以堆理论上可以接近3G，实际上在2G-3G之间）。 能否产生碎片： 栈的操作与数据结构中的栈用法是类似的。‘后进先出’的原则，以至于不可能有一个空的内存块从栈被弹出。因为在它弹出之前，在它上面的后进栈的数据已经被弹出。它是严格按照栈的规则来执行。但是堆是通过new/malloc随机申请的空间，频繁的调用它们，则会产生大量的内存碎片。这是不可避免地。 什么是野指针/悬空指针，如何避免？ 野指针就是没有被初始化的指针 悬空指针是指指针指向的内存空间已被释放或不再有效。 如何避免： 野指针：指针变量未及时初始化 => 定义指针变量及时初始化，要么置空。 悬空指针：指针free或delete之后没有及时置空 => 释放操作后立即置空。 使用时不要超出指针作用域 使用智能指针 数组和指针的区别？ 数组：数组是用于储存多个相同类型数据的集合。 数组名是首元素的地址。 指针：指针相当于一个变量，但是它和普通变量不一样，它存放的是其它变量在内存中的地址。指针名指向了内存的首地址。 区别： 赋值：同类型指针变量可以相互赋值；数组不行，只能一个一个元素的赋值或拷贝 存储方式： 数组：数组在内存中是连续存放的，开辟一块连续的内存空间。数组是根据数组的下进行访问的，数组的存储空间，不是在静态区就是在栈上。 指针：指针本身就是一个变量，作为局部变量时存储在栈上。 sizeof：数组所占存储空间的内存大小：sizeof（数组名）/sizeof（数据类型） 32位平台下，sizeof（指针名）=4，64位平台下，sizeof（指针名）=8。 引用和指针的区别？ 指针是实体，占用内存空间；引用是别名，与变量共享内存空间。 指针不用初始化或初始化为NULL；引用定义时必须初始化。 指针中途可以修改指向；引用不可以。 指针可以为NULL；引用不能为空。 sizeof(指针)计算的是指针本身的大小；而sizeof(引用)计算的是它引用的对象的大小。 如果返回的是动态分配的内存或对象，必须使用指针，使用引用会产生内存泄漏。 指针使用时需要解引用；引用使用时不需要解引用‘*’。 有二级指针；没有二级引用。 数组指针与指针数组的区别？ 数组指针是一个指针变量，指向了一个一维数组， 如int (*p)[4]，(*p)[4]就成了一个二维数组，p也称行指针；指针数组是一个数组，只不过数组的元素存储的是指针变量, 如int *p[4]。 指针函数与函数指针的区别？ 指针函数本质是一个函数，其返回值为指针。 函数指针本质是一个指针，其指向一个函数。 指针函数：int *fun(int x,int y); 函数指针：int (*fun)(int x,int y); 指针函数返回一个指针。 函数指针使用过程中指向一个函数。通常用于回调函数的应用场景。 回调函数就是一个通过函数指针调用的函数。如果你把函数的指针（地址）作为参数传递给另一个函数，当这个指针被用为调用它所指向的函数时，我们就说这是回调函数。 const的作用？ 指针常量（顶层const）和常量指针（底层const） const修饰普通类型的变量，告诉编译器某值是保持不变的。 const 修饰指针变量，根据const出现的位置和出现的次数分为三种 指向常量的指针：指针指向一个常量对象，目的是防止使用该指针来修改指向的值。 常指针：将指针本身声明为常量，这样可以防止改变指针指向的位置。 指向常量的常指针：一个常量指针指向一个常量对象。 const修饰参数传递，可以分为三种情况。 值传递的 const 修饰传递，一般这种情况不需要 const 修饰 当 const 参数为指针时，可以防止指针被意外篡改。 自定义类型的参数传递，需要临时对象复制参数，对于临时对象的构造，需要调用构造函数，比较浪费时间，因此我们采取 const 外加引用传递的方法。 const修饰函数返回值，分三种情况。 const 修饰内置类型的返回值，修饰与不修饰返回值作用一样。 const 修饰自定义类型的作为返回值，此时返回的值不能作为左值使用，既不能被赋值，也不能被修改。 const 修饰返回的指针或者引用，是否返回一个指向 const 的指针，取决于我们想让用户干什么。 const修饰类成员函数 const 修饰类成员函数，其目的是防止成员函数修改被调用对象的值，如果我们不想修改一个调用对象的值，所有的成员函数都应当声明为 const 成员函数。 常量对象可以调用类中的 const 成员函数，但不能调用非 const 成员函数; (原因:对象调用成员函数时，在形参列表的最前面加一个形参 this，但这是隐式的。this 指针是默认指向调用函数的当前对象的，所以，很自然， this 是一个常量指针 test const，因为不可以修改 this 指针代表的地址。但当成员函数的参数列表(即小括号) 后加了 const 关键字(void print() const;)，此成员函数为常量成员函数，此时它的隐式this形参为 const test const，即不可以通过 this 指针来改变指向对象的值。 static的作用？ 控制变量的存储方式和可⻅性 1.静态局部变量 用于函数体内部修饰变量 （1）该变量在全局数据区分配内存(局部变量在栈区分配内存); （2）静态局部变量在程序执行到该对象的声明处时被首次初始化，即以后的函数调用不再进行初始化(局部变量每次函数调用都会被初始化); （3）静态局部变量一般在声明处初始化，如果没有显式初始化，会被程序自动初始化为0(局部变量不会被初始化); （4）它始终驻留在全局数据区，直到程序运行结束。但其作用域为局部作用域，也就是不能在函数体外面使用它(局部变量在栈区，在函数结束后立即释放内存); 2.静态全局变量和静态函数 定义在函数体外，用于修饰全局变量，表示该变量只在本文件可见。 （1）静态全局变量不能被其它文件所用(全局变量可以); （2）其它文件中可以定义相同名字的变量，不会发生冲突(自然了，因为static隔离了文件，其它文件使用相同的名字的变量，也跟它没关系了); 3.静态成员变量 所有的对象都只维持一份拷贝，可以实现不同对象间的数据共享； 不需要实例化对象即可访问 注意不能再类内部初始化！要在类外部初始化，初始化时不加static！(如果类外定义函数时在函数名前加了static，因为作用域的限制，就只能在当前cpp里用，歧义) 4.静态成员函数 这个函数不接受this指针，只能访问类的静态成员 这个函数不需要实例化对象即可访问 为什么静态成员变量不能在类内初始化？ 因为静态成员属于整个类，而不属于某个对象，如果在类内初始化，会导致每个对象都包含该静态成员，这是矛盾的。 为什么静态成员函数不能访问非静态成员？ 静态成员函数不属于任何一个对象，因此C++规定静态成员函数没有this指针。既然它没有指向某一对象，也就无法对一个对象中的非静态成员进行访问。 为什么要少使用#define？ 由程序编译的四个过程，知道宏是在预编译阶段被展开的。在预编译阶段是不会进行语法检查、语义分析的，宏被暴力替换，正是因为如此，如果不注意细节，宏的使用很容易出现问题。比如在表达式中忘记加括号等问题。 正因为如此，在C++中为了安全性，我们就要少用宏。 不带参数的宏命令我们可以用常量const来替代，比如const int PI = 3.1415，可以起到同样的效果，而且还比宏安全，因为这条语句会在编译阶段进行语法检查。 而带参数的宏命令有点类似函数的功能，在C++中可以使用内联函数或模板来替代，内联函数与宏命令功能相似，是在调用函数的地方，用函数体直接替换。但是内联函数比宏命令安全，因为内联函数的替换发生在编译阶段，同样会进行语法检查、语义分析等，而宏命令发生在预编译阶段，属于暴力替换，并不安全。 什么是内联函数？ 内联函数是通常与类一起使用。如果一个函数是内联的，那么在编译时，编译器会把该函数的代码副本放置在每个调用该函数的地方。 内联函数的作用：内联函数在调用时，是将调用表达式用内联函数体来替换。避免函数调用的开销。 为什么使用内联函数？ 函数调用是有调用开销的，执行速度要慢很多，调用函数要先保存寄存器，返回时再恢复，复制实参等等。 如果本身函数体很简单，那么函数调用的开销将远大于函数体执行的开销。为了减少这种开销，我们才使用内联函数。 内联函数使用的条件 以下情况不宜使用内联： （1）如果函数体内的代码比较长，使用内联将导致内存消耗代价较高。 （2）如果函数体内出现循环，那么执行函数体内代码的时间要比函数调用的开销大。 内联不是什么时候都能展开的，一个好的编译器将会根据函数的定义体，自动地取消不符合要求的内联。 四种强制类型转换 xxx_cast (expression); static_cast 最常见的类型转换。它可以用于基本数据类型之间的转换，也可以用于指向父类和子类之间的指针或引用的转换 基本数据类型之间的转换。 将任何类型转换为void类型。 将空指针转换成目标类型的指针。 用于类层次结构中基类和派生类之间指针或引用的转换。向上转换（派生类转换为基类）是安全的；向下转换（基类转换为派生类）没有动态类型检查，是不安全的。 int i = 10; double d = static_cast(i); // 整型转为浮点型 dynamic_cast 主要用于处理基类和派生类之间的转换。如果类型转换不安全，它会返回空指针NULL。这是唯一一种在运行时执行类型检查的转换。要求转换的类具有多态性质(虚函数)。type-id:类的指针、引用、void* Base *b = new Derived(); Derived *d = dynamic_cast(b); // 基类指针转为派生类指针 if (d != nullptr) { // 转换成功 } else { // 转换失败 } const_cast 用于修改常量对象的常量属性。需要注意的是，使用 const_cast 去掉常量性质并修改数据可能导致未定义的行为。**只能用于转换指针或引用，type_id和expression的类型是一样的。 int num = 100; const int* p1 = &num; //将常量指针转换为普通类型指针，去除const属性 int* p2 = const_cast(p1); *p2 = 200; int a = 100; const int& ra = a; //将常量引用转换为普通类型引用，去除const属性 int& ra1 = const_cast(ra); ra1 = 200; reinterpret_cast 允许进行任何指针或整型的转换。它可以将任何类型的指针转换为任何其他类型的指针，也可以将任何类型的指针转换，要转换的类型必须是指针、引用或算术类型。 char c = 'a'; int d = reinterpret_cast(c); int* p=NULL; float* q = NULL; p = reinterpret_cast(q); q = reinterpret_cast(q); 智能指针 智能指针是利用了一种叫做RAII（资源获取即初始化）的技术对普通的指针进行封装，智能指针实质是一个对象，行为表现的却像一个指针。智能指针就是一个类，当超出了类的作用域时，类会自动调用析构函数，自动释放资源。这样程序员就不用再担心内存泄露的问题了。 C++里面有四个指针：auto_ptr、unique_ptr、shared_ptr、weak_ptr，auto_ptr被C++11弃用（存在潜在的内存崩溃问题）。 shared_ptr shared_ptr 实现共享式拥有概念，智能指针可以指向相同对象。该对象和其相关资源会在“最后一个引用被销 毁”时候释放。 实现原理：有一个引用计数的指针类型变量，专门用于引用计数，使用拷贝构造函数和赋值拷贝构造函数时，引用计数加1，当引用计数为0时，释放资源 weak_ptr 解决shared_ptr内存泄露，共享指针的循环引用计数问题：当两个类中相互定义shared_ptr成员变量，同时对象相互赋值时，就会产生循环引用计数问题，最后引用计数无法清零，资源得不到释放。 可以使用weak_ptr，weak_ptr是弱引用，weak_ptr的构造和析构不会引起引用计数的增加或减少。我们可以将其中一个改为weak_ptr指针就可以了。 unique_ptr unique指针规定一个智能指针独占一块内存资源。当两个智能指针同时指向一块内存，编译报错。 保证同一时间内只有一个智能指针可以指向该对象。实现只需要将拷贝构造函数和赋值拷贝构造函数申明为private或delete。不允许拷贝构造函数和赋值操作符 unique_ptr p3 (new string (auto));//#4 unique_ptr p4;//#5 p4 = p3;//此时会报错 智能指针成员函数 //unique_ptr release(); // 返回一个指向被管理对象的指针，并释放所有权 reset(); //替换被管理对象 swap(); //交换被管理对象 get(); //返回指向被管理对象的指针 //shared_ptr reset(); //替换被管理对象 swap(); //交换被管理对象 get(); //返回指向被管理对象的指针 use_count(); //返回 shared_ptr 所指对象的引用计数 //weak_ptr reset(); //替换被管理对象 swap(); //交换被管理对象 use_count(); //返回 shared_ptr 所指对象的引用计数 lock(); //创建管理被引用的对象的shared_ptr 面向对象 面对对象和面对过程的区别？ 面向过程的编程思想，就是关注问题解决的过程，按顺序一步一步执行解决问题。而面向对象的编程思想，是把构成问题的各个事务分解成各个对象，即问题建模。建立对象的目的不是为了完成一个步骤，而是为了描述一个事务在解决问题中经过的步骤和行为。 C++有几种构造函数？ 默认构造函数 初始化构造函数（有参数） 拷贝构造函数 移动构造函数（move和右值引用） 委托构造函数 转换构造函数 #include using namespace std; class Student{ public: Student(){//默认构造函数，没有参数 this->age = 20; this->num = 1000; }; Student(int a, int n):age(a), num(n){}; //初始化构造函数，有参数和参数列表 Student(const Student& s){//拷贝构造函数，这里与编译器生成的一致 this->age = s.age; this->num = s.num; }; Student(int r){ //转换构造函数,形参是其他类型变量，且只有一个形参 this->age = r; this->num = 1002; }; ~Student(){} public: int age; int num; }; int main(){ Student s1; Student s2(18,1001); int a = 10; Student s3(a); Student s4(s3); printf(\"s1 age:%d, num:%d\\n\", s1.age, s1.num); printf(\"s2 age:%d, num:%d\\n\", s2.age, s2.num); printf(\"s3 age:%d, num:%d\\n\", s3.age, s3.num); printf(\"s2 age:%d, num:%d\\n\", s4.age, s4.num); return 0; } //运行结果 //s1 age:20, num:1000 //s2 age:18, num:1001 //s3 age:10, num:1002 //s2 age:10, num:1002 成员初始化列表 用初始化列表会快一些的原因是，对于类型，它少了一次调用构造函数的过程，而在函数体中赋值则会多一次调用。而对于内置数据类型则没有差别。 class complex { public: complex(double r = 0, double i = 0) : re(r), im(i) {} complex& operator += (const complex&) double real () const { return re; } double imag () const { return im; } private: double re, im; friend complex& __doapl (complex* , const complex&); } 拷贝构造函数和赋值运算符重载的区别？ 赋值运算符 对象存在，用别的对象给它赋值，这属于重载“=”号运算符的范畴，“=”号两侧的对象都是已存在的。 拷贝构造函数是函数，赋值运算符是运算符重载。 拷贝构造函数会生成新的类对象，赋值运算符不能。 拷贝构造函数是直接构造一个新的类对象，所以在初始化对象前不需要检查源对象和新建对象是否相同；赋值运算符需要上述操作并提供两套不同的复制策略，另外赋值运算符中如果原来的对象有内存分配则需要先把内存释放掉。 形参传递是调用拷贝构造函数（调用的被赋值对象的拷贝构造函数），但并不是所有出现\"=\"的地方都是使用赋值运算符，如下： Student s; Student s1 = s; // 调用拷贝构造函数 Student s2; s2 = s; // 赋值运算符操作 注：类中有指针变量时要重写析构函数、拷贝构造函数和赋值运算符。 拷贝构造函数的参数类型为什么必须是引用? 如果拷贝构造函数中的参数不是一个引用，即形如CClass(const CClass c_class)，那么就相当于采用了传值的方式(pass-by-value)，而传值的方式会调用该类的拷贝构造函数，从而造成无穷递归地调用拷贝构造函数。因此拷贝构造函数的参数必须是一个引用。否则无法完成拷贝，而且栈也会满。 什么情况下会调用拷⻉构造函数？ 类的对象需要拷⻉时，拷⻉构造函数将会被调用，以下的情况都会调用拷⻉构造函数: 一个对象以值传递的方式传入函数体，需要拷⻉构造函数创建一个临时对象压入到栈空间中。 一个对象以值传递的方式从函数返回，需要执行拷⻉构造函数创建一个临时对象作为返回值。 一个对象需要通过另外一个对象进行初始化。 左值和右值？ C++ 中有两种类型的表达式： 左值（lvalue）：指向内存位置的表达式被称为左值（lvalue）表达式。左值可以出现在赋值号的左边或右边。 右值（rvalue）：术语右值（rvalue）指的是存储在内存中某些地址的数值。右值是不能对其进行赋值的表达式，也就是说，右值可以出现在赋值号的右边，但不能出现在赋值号的左边。 变量是左值，因此可以出现在赋值号的左边。数值型的字面值是右值，因此不能被赋值，不能出现在赋值号的左边。 右值引用的作用？ C++11引入右值引用&&主要是为了实现移动语义和完美转发。 移动语义为了避免临时对象的拷贝，为类增加移动构造函数。 完美转发，就是通过一个函数将参数继续转交给另一个函数进行处理，原参数可能是右值，可能是左值，如果还能继续保持参数的原有特征，那么它就是完美的。 移动语义的原理？ 移动语义为了避免临时对象的拷贝，为类增加移动构造函数。移动构造函数与拷贝构造不同，它并不是重新分配一块新的空间同时将要拷贝的对象复制过来，而是\"拿\"了过来，将自己的指针指向别人的资源，然后将别人的指针修改为nullptr 类的访问权限有几种？ 公有成员（变量和函数）允许类成员和类外的任何访问，由public限定； 私有成员（变量和函数）只限于类成员访问，由private限定； 受保护成员（变量和函数）允许类成员和派生类成员访问，不允许类外的任何访问。所以protected对外封闭，对派生类开放。 继承类型和访问属性 当一个类派生自基类，该基类可以被继承为 public、protected 或 private 几种类型。 我们几乎不使用 protected 或 private 继承，通常使用 public 继承。当使用不同类型的继承时，遵循以下几个规则： 公有继承（public）：当一个类派生自公有基类时，基类的公有成员也是派生类的公有成员，基类的保护成员也是派生类的保护成员，基类的私有成员不能直接被派生类访问，但是可以通过调用基类的公有和保护成员来访问。 保护继承（protected）： 当一个类派生自保护基类时，基类的公有和保护成员将成为派生类的保护成员。 私有继承（private）：当一个类派生自私有基类时，基类的公有和保护成员将成为派生类的私有成员。 总结: 不管是哪种继承方式，派生类中新增成员可以访问基类的公有成员和保护成员，无法访问私有成员。但是只有公有继承中，派生类的对象能访问基类的公有成员。使用友元（friend）可以访问保护成员和私有成员。 多态的实现？ 利用虚函数，基类指针指向基类对象时就使用基类的成员（包括成员函数和成员变量），指向派生类对象时就使用派生类的成员。换句话说，基类指针可以按照基类的方式来做事，也可以按照派生类的方式来做事，它有多种形态，或者说有多种表现方式，我们将这种现象称为多态（Polymorphism）。 多态其实一般就是指继承加虚函数实现的多态，多态可以分为静态多态和动态多态。静态多态其实就是重载，因为静态多态是指在编译时期就决定了调用哪个函数，根据参数列表来决定;动态多态是指通过子类重写父类的虚函数来实现的，因为是在运行期间决定调用的函数，所以称为动态多态，一般情况下我们不区分这两个时所说的多态就是指动态多态。 虚函数的实现原理 C++实现虚函数的原理是虚函数表+虚表指针。 当一个类里存在虚函数时，编译器会为类创建一个虚函数表，虚函数表是一个数组，数组的元素存放的是类中虚函数的地址。 同时为每个类的对象添加一个隐藏成员，该隐藏成员保存了指向该虚函数表的指针。该隐藏成员占据该对象的内存布局的最前端。 虚函数表在什么时候创建？每个对象都有一份虚函数表吗？ 当一个类里存在虚函数时，编译器会为类创建一个虚函数表，发生在编译期。 虚函数表只有一份，而有多少个对象，就对应多少个虚函数表指针。 纯虚函数？ virtual void fun() = 0; 纯虚函数的类称为抽象类（Abstract Class）。之所以说它抽象，是因为它无法实例化，也就是无法创建对象。原因很明显，纯虚函数没有函数体，不是完整的函数，无法调用，也无法为其分配内存空间。 抽象类通常是作为基类，让派生类去实现纯虚函数。派生类必须实现纯虚函数才能被实例化。 析构函数必须为虚函数吗？构造函数可以为虚函数吗？ C++默认析构函数不是虚函数，因为申明虚函数会创建虚函数表，占用一定内存，当不存在继承的关系时，析构函数不需要申明为虚函数。 若存在继承关系时，析构函数必须申明为虚函数，这样父类指针指向子类对象，释放基类指针时才会调用子类的析构函数释放资源，否则内存泄漏。 构造函数不能为虚函数，当申明一个函数为虚函数时，会创建虚函数表，那么这个函数的调用方式是通过虚函数表来调用。若构造函数为虚函数，说明调用方式是通过虚函数表调用，需要借助虚表指针，但是没构造对象，哪里来的虚表指针？但是没有虚表指针，怎么访问虚函数表从而调用构造函数呢？这就成了一个先有鸡还是先有蛋的问题。 构造与析构的顺序？ 构造顺序：基类构造函数>对象成员构造函数>子类构造函数 析构顺序：子类析构函数>对象成员析构函数>基类析构函数 从里向外构造，从外向里析构。 深拷贝与浅拷贝的区别？ 浅拷贝只复制指向某个对象的指针，而不复制对象本身，新旧对象还是共享同一块内存。但深拷贝会另外创造一个一模一样的对象，新对象跟原对象不共享内存，修改新对象不会改到原对象。 什么是this指针？ 在每一个成员函数中都包含一个特殊的指针，这个指针的名字是固定的，称为this指针。它是指向本类对象的指针，它的值是当前被调用的成员函数所在的对象的起始地址。 this是一个指针，它时时刻刻指向你这个实例本身。 this在成员函数的开始执行前构造，在成员的执行结束后清除。 重载、重写、隐藏？ 重载overload 函数名相同，参数列表不同（参数类型、参数顺序),不能用返回值区分。 特点：作用域相同；函数名相同；参数列表必须不同，但返回值无要求； 特殊情况：若某一重载版本的函数前面有virtual关键字修饰，则表示它是虚函数，但它也是重载的一个版本。 作用效果：编译器根据函数不同的参数列表，将函数与函数调用进行早绑定，重载与多态无关，与面向对象无关，它只是一种语言特性。 重写override 派生类重定义基类的虚函数，既会覆盖基类的虚函数(多态)。 特点：作用域不同；函数名、参数列表、返回值相同；基类函数是virtual； 特殊情况：若派生类重写函数是一个重载版本，那么基类的其他同名重载函数将在子类中隐藏。 作用效果：父类指针和引用指向子类的实例时，通过父类指针或引用可以调用子类的函数，这就是C++的多态。 隐藏hide 隐藏指的是某些情况下，派生类中的函数屏蔽了基类中的同名函数。 两个函数参数相同，但是基类函数不是虚函数。和重写的区别在于基类函数是否是虚函数。 两个函数参数不同，无论基类函数是不是虚函数，都会被隐藏。和重载的区别在于两个函数不在同一个类中。 空类大小？ 空类sizeof大小为1，这是为了让对象的实例能够相互区别。 友元类和友元函数？ 友元类的所有成员函数都是另一个类的友元函数，都可以访问另一个类中的隐藏信息（包括私有成员和保护成员）。但是另一个类里面也要相应的进行声明。 友元函数是定义在类外的普通函数，不属于任何类，可以访问其他类的私有成员和保护成员。但是需要在类的定义中声明所有可以访问它的友元函数。 友元的正确使用能提高程序的运行效率，但同时也破坏了类的封装性和数据的隐藏性，导致程序可维护性变差。 模板 程序所实现的功能基本相同，不同的仅是数据类型不同。而模板正是一种专门处理不同数据类型的机制。 #include using namespace std; template//函数模板 type1 Max(type1 a,type2 b) { return a > b ? a : b; } void main() { cout 该模板有个比较隐晦的bug，那就是a、b只有在能进行转型的时候才能进行比较，否则 a > b 这一步是会报错的，这个时候往往需要对于 > 号进行重载。 模版特例化 定义:对单一模板提供的一个特殊实例，它将一个或多个模板参数绑定到特定的类型或值上 模板函数特例化 必须为原函数模板的每个模板参数都提供实参，且使用关键字template后跟一个空尖括号对<>，表明将原模板的所有模板参数提供实参 注意 模板及其特例化版本应该声明在同一个头文件中，且所有同名模板的声明应该放在前面，后面放特例化版本。 类模板特例化 原理类似函数模板，不过在类中，我们可以对模板进行特例化，也可以对类进行部分特例化。对类进行特例化时，仍然用template<>表示是一个特例化版本。 类模板的部分特例化 不必为所有模板参数提供实参，可以指定一部分而非所有模板参数，一个类模板的部分特例化本身仍是一个模板，使用它时还必须为其特例化版本中未指定的模板参数提供实参(特例化时类名一定要和原来的模板相同，只是参数类型不同，按最佳匹配原则，哪个最匹配，就用相应的模板) explicit explicit 关键字只能用于类内部的构造函数声明上 被explicit修饰的构造函数的类，不能发生相应的隐式类型转换，只能以显式的方式进行类型转换 final override final来限制某个类不能被继承，或者某个虚函数不能被重写。如果修饰函数，final只能修饰虚函数，并且要放到类或者函数的后面 override确保在派生类中声明的重写函数与基类的虚函数有相同的签名，同时也明确表明将会重写基类的虚函数，还可以防止因疏忽把本来想重写基类的虚函数声明成隐藏。 extern 关键字：在C++中，导入C函数的关键字是extern，表达形式为extern “C”， extern \"C\"的主要作用就是为了能够正确实现C++代码调用其他C语言代码。加上extern \"C\"后，会指示编译器这部分代码按C语言的进行编译，而不是C++的。 编译区别：由于C++支持函数重载，因此编译器编译函数的过程中会将函数的参数类型也加到编译后的代码中，而不仅仅是函数名；而C语言并不支持函数重载，因此编译C语言代码的函数时不会带上函数的参数类型，一般只包括函数名。 assert assert(expr) 如果expr表达式为假，assert输出信息并终止程序执行，如果为真，assert什么也不做。 volatile mutable volatile的变量是说这变量可能会被意想不到地改变，系统总是重新从它所在的内存读取数据。每次用到这个变量的值的时候都要去重新读取这个变量的值，而不是读寄存器内的备份。多线程中被几个任务共享的变量需要定义为volatile类型。 mutable是为了突破const的限制而设置的。被mutable修饰的变量，将永远处于可变的状态，即使在一个const函数中，甚至结构体变量或者类对象为const，其mutable成员也可以被修改。mutable在类中只能够修饰非静态数据成员。 内存管理 什么是内存泄露？ 简单地说就是申请了一块内存空间，使用完毕后没有释放掉。 （1）new和malloc申请资源使用后，没有用delete和free释放； （2）子类继承父类时，父类析构函数不是虚函数。 （3）比如文件句柄、socket、自定义资源类没有使用对应的资源释放函数。 （4）shared_ptr共享指针成环，造成循环引用计数，资源得不到释放。 如何避免内存泄漏？ 良好的编码习惯，使用了内存分配的函数，一旦使用完毕,要记得使用其相应的函数释放掉。将分配的内存的指针以链表的形式自行管理，使用完毕之后从链表中删除，程序结束时可检查改链表。使用智能指针。一些常见的工具插件可以帮助检测内存泄露，如ccmalloc、Dmalloc、Leaky、Valgrind等等。 new/delete和malloc/free的异同？ int *p = new int[2]; int *q = (int *)malloc(2*sizeof(int)); 都可用于内存的动态申请和释放 new是操作符，而malloc是函数。 new在调用的时候先分配内存，在调用构造函数，释放的时候调用析构函数；而malloc没有构造函数和析构函数。 malloc需要给定申请内存的大小，返回的指针需要强转；new会调用构造函数，不用指定内存的大小，返回指针不用强转。 new可以被重载；malloc不行 new分配内存更直接和安全。 new发生错误抛出异常，malloc返回null new/delete实现原理？ new的实现过程是：首先调用名为operator new的标准库函数，分配足够大的原始为类型化的内存，以保存指定类型的一个对象；接下来运行该类型的一个构造函数，用指定初始化构造对象；最后返回指向新分配并构造后的的对象的指针 delete的实现过程：对指针指向的对象运行适当的析构函数；然后通过调用名为operator delete的标准库函数释放该对象所用内存 malloc/free实现原理？ 1、 在标准C库中，提供了malloc/free函数分配释放内存，这两个函数底层是由brk、mmap、，munmap这些系统调用实现的; 2、 brk是将数据段(.data)的最高地址指针_edata往高地址推,mmap是在进程的虚拟地址空间中（堆和栈中间，称为文件映射区域的地方）找一块空闲的虚拟内存。这两种方式分配的都是虚拟内存，没有分配物理内存。在第一次访问已分配的虚拟地址空间的时候，发生缺页中断，操作系统负责分配物理内存，然后建立虚拟内存和物理内存之间的映射关系； 3、 malloc小于128k的内存，使用brk分配内存，将_edata往高地址推；malloc大于128k的内存，使用mmap分配内存，在堆和栈之间找一块空闲内存分配；brk分配的内存需要等到高地址内存释放以后才能释放，而mmap分配的内存可以单独释放。当最高地址空间的空闲内存超过128K（可由M_TRIM_THRESHOLD选项调节）时，执行内存紧缩操作（trim）。在上一个步骤free的时候，发现最高地址空闲内存超过128K，于是内存紧缩。 4、 malloc是从堆里面申请内存，也就是说函数返回的指针是指向堆里面的一块内存。操作系统中有一个记录空闲内存地址的链表。当操作系统收到程序的申请时，就会遍历该链表，然后就寻找第一个空间大于所申请空间的堆结点，然后就将该结点从空闲结点链表中删除，并将该结点的空间分配给程序。 什么是字节对齐？ 为了使CPU能够对变量进行快速的访问，变量的起始地址应该具有某些特性，即所谓的“对齐”，比如4字节的int型，其起始地址应该位于4字节的边界上，即起始地址能够被4整除，也即“对齐”跟数据在内存中的位置有关。如果一个变量的内存地址正好位于它长度的整数倍，他就被称做自然对齐。 为什么要字节对齐？ （1）需要字节对齐的根本原因在于CPU访问数据的效率问题。 （2）一些系统对对齐要求非常严格，比如sparc系统，如果取未对齐的数据会发生错误，而在x86上就不会出现错误，只是效率下降。 （3）各个硬件平台对存储空间的处理上有很大的不同。一些平台对某些特定类型的数据只能从某些特定地址开始存取。比如有些平台每次读都是从偶地址开始 结构体字节对齐三原则： 1.每个数据成员存储起始位置要从该成员大小的整数倍开始 2.结构体作为成员时应从内部最大元素的整数倍地址开始存储 3.结构体总大小为内部最大成员的整数倍 GDB g++ -g 添加gdb调试选项 linux系统支持gdb，mac支持lldb。https://lldb.llvm.org/use/map.html为gdb和lldb命令对照表。 先编译生成.out文件g++ -g -std=c++11 a.cpp，gdb a.out进入调试页面，最后r或run运行。 b打断点，info breeak查看断点信息，del 1删除断点。 n或next继续执行 p、print打印变量或变量地址 s、step进入函数调试 shell ls可以使用终端命令等，set logging on打开日志模式 watchpoint查看变量是否变化，info查看watchpoint信息。 ulimit -a 调试core文件 STL vector deque（双端数组） list（双向链表） queue stack set/unordered_set map/unordered_map 是否支持迭代器 × × 尾部添加 push_back push_back push_back push 尾部删除 pop_back pop_back pop_back 首部添加 push_front push_front push 首部删除 pop_front pop_front pop pop 插入（迭代器） insert insert insert insert insert 删除（迭代器） erase erase erase erase erase 改变大小 resize resize resize 交换内容 swap swap swap swap swap 清除 clear clear clear clear clear 是否为空 empty empty empty empty empty empty empty 大小 size size size size size size size 第一个元素 front front front front 最后一个元素 back back back back 访问元素 at() at() at() top（栈顶） 指定键的个数 count count 寻找指定键 存在返回迭代器，反之返回s.end() find find vector> dp(n,vector(m,0)) n行m列二维数组 vector访问元素的速度要比deque快 set不允许出现重复 所有的元素都会被自动排序（默认从小到大） 不能直接修改它的元素值 multiset 允许出现键值重复，unordered_set unordered_multiset元素不会自动排序 map中是pair p(key,value) map.first是key 只出现一次 map.second是value map[key]=value map[x]++ 把key放在map中计数 迭代器 迭代器是类模板不是指针（表现得像指针） container::iterator iter container::const_iterator citer *iter :返回迭代器iter所指元素引用 iter->mem :等价于(*iter).mem，解引用iter并获取该元素的名为mem的成员 ++iter :令iter指示容器中的下一个元素 --iter :令iter指示容器中的上一个元素 iter + n:迭代器加上一个整数仍得一个迭代器，迭代器指示的新位置与原来相比向前移动了若干个元素。 iter - n:迭代器减去一个整数仍得一个迭代器，迭代器指示的新位置与原来相比向后移动了若干个元素。 lambda 函数式编程 lambda 的形式 C++ 没有为 lambda 表达式引入新的关键字，并没有“lambda”这样的词汇，而是用了一个特殊的形式“[]”，术语叫“lambda 引出符”（lambda introducer）。在 lambda 引出符后面，就可以像普通函数那样，用圆括号声明入口参数，用花括号定义函数体。 auto f1 = [](){}; // 相当于空函数，什么也不做 auto f2 = []() // 定义一个lambda表达式 { cout C++ 里，每个 lambda 表达式都会有一个独特的类型，而这个类型只有编译器才知道，我们是无法直接写出来的，所以必须用 auto。 不过，因为 lambda 表达式毕竟不是普通的变量，所以 C++ 也鼓励程序员尽量“匿名”使用 lambda 表达式。也就是说，它不必显式赋值给一个有名字的变量，直接声明就能用。 由于“匿名”，lambda 表达式调用完后也就不存在了（也有被拷贝保存的可能），这就最小化了它的影响范围，让代码更加安全。 vector v = {3, 1, 8, 5, 0}; // 标准容器 cout = 5; // 用做算法的谓词判断条件 } // lambda表达式结束 ) find_if()的第三个参数是一个 lambda 表达式的谓词。这个 lambda 表达式以值的方式捕获 value，并在 lambda 参数大于 value 时返回 true。 lambda的变量捕获 lambda 的“捕获”功能需要在“[]”里做文章，由于实际的规则太多太细，记忆、理解的成本高，所以记住几个要点： “[=]”表示按值捕获所有外部变量，表达式内部是值的拷贝，并且不能修改； “[&]”是按引用捕获所有外部变量，内部以引用的方式使用，可以修改； 也可以在“[]”里明确写出外部变量名，指定按值或者按引用捕获，C++ 在这里给予了非常大的灵活性。 int x = 33; // 一个外部变量 auto f1 = [=]() // lambda表达式，用“=”按值捕获 { //x += 10; // x只读，不允许修改 }; auto f2 = [&]() // lambda表达式，用“&”按引用捕获 { x += 10; // x是引用，可以修改 }; auto f3 = [=, &x]() // lambda表达式，用“&”按引用捕获x，其他的按值捕获 { x += 20; // x是引用，可以修改 }; 在使用捕获功能的时候要小心，对于“就地”使用的小 lambda 表达式，可以用“[&]”来减少代码量，保持整洁；而对于非本地调用、生命周期较长的 lambda 表达式应慎用“[&]”捕获引用，而且，最好是在“[]”里显式写出变量列表，避免捕获不必要的变量。 class DemoLambda final { private: int x = 0; public: auto print() // 返回一个lambda表达式供外部使用 { return [this]() // 显式捕获this指针 { cout 泛型的 lambda C++14 里，lambda 表达式可以实现“泛型化”，相当于简化了的模板函数，具体语法利用了 auto： auto f = [](const auto& x) // 参数使用auto声明，泛型化 { return x + x; }; cout = default 和 = delete = default 和 =delete 是 C++11 新增的专门用于六大基本函数的用法，对于比较重要的构造函数和析构函数，应该用= default的形式，明确地告诉编译器：“应该实现这个函数，但我不想自己写。”这样编译器就得到了明确的指示，可以做更好的优化。 class DemoClass final { public: DemoClass() = default; // 明确告诉编译器，使用默认实现 ~DemoClass() = default; // 明确告诉编译器，使用默认实现 }; 另一种 = delete 的形式。表示明确地禁用某个函数形式，且不限于构造 / 析构，可以用于任何函数（成员函数、自由函数）。比如说，如果想要禁止对象拷贝，就可以用这种语法显式地把拷贝构造和拷贝赋值delete掉，让外界无法调用。 class DemoClass final { public: DemoClass(const DemoClass&) = delete; // 禁止拷贝构造 DemoClass& operator=(const DemoClass&) = delete; // 禁止拷贝赋值 }; Copyright © YZJ 2022 all right reserved，powered by Gitbook更新时间： 2023-08-12 09:20:46 "},"计算机网络.html":{"url":"计算机网络.html","title":"计算机网络","keywords":"","body":"计算机网络 OSI TCP/IP OSI(Open System Interconnect)七层协议模型 各层功能 物理层: 通过媒介传输比特,确定机械及电气规范，传输单位为bit，主要包括的协议为：IEE802.3 CLOCK RJ45 数据链路层: 将比特组装成帧和点到点的传递,传输单位为帧,主要包括的协议为MAC VLAN PPP 网络层：将分组从源端传送到目的端，提供网络互连，传输单位为包,主要包括的协议为IP ARP ICMP 传输层：提供可靠端到端的报文传递和差错控制，传输单位为报文,主要包括的协议为TCP UDP 会话层：建立、管理和终止会话，传输单位为SPDU，主要包括的协议为RPC NFS 表示层: 对数据进行翻译、加密和压缩,传输单位为PPDU，主要包括的协议为JPEG ASII 应用层: 各种应用软件（应用程序及接口）,传输单位为APDU，主要包括的协议为 FTP HTTP DNS TCP/IP 体系结构 应用层 HTTP：超文本传输协议，在浏览器与服务器间传送文档。 DNS（Domain Name Service，域名服务）协议提供机器域名到IP地址的转换。DNS是一套分布式的域名服务系统。每个DNS服务器上都存放着大量的机器名和IP地址的映射，并且是动态更新的。众多网络客户端程序都使用DNS协议来向DNS服务器查询目标主机的IP地址。(UDP传输) 当用户输入域名时，浏览器先检查自己的缓存中是否包含这个域名映射的ip地址，有解析结束。 2）若没命中，则检查操作系统缓存（如Windows的hosts）中有没有解析过的结果，有解析结束。 3）若无命中，则请求本地域名服务器解析（LDNS）。 4）若LDNS没有命中就直接跳到根域名服务器请求解析。根域名服务器返回给LDNS一个 主域名服务器地址。 5）此时LDNS再发送请求给上一步返回的gTLD（ 通用顶级域）， 接受请求的gTLD查找并返回这个域名对应的Name Server的地址 6）Name Server根据映射关系表找到目标ip，返回给LDNS LDNS缓存这个域名和对应的ip， 把解析的结果返回给用户，用户根据TTL值缓存到本地系统缓存中，域名解析过程至此结束 SMTP协议：简单邮件传送协议 FTP协议：文件传输协议 RIP 协议：距离矢量路由选择协议。 传输层 TCP协议（Transmission Control Protocol，传输控制协议）为应用层提供可靠的、面向连接的和基于流（stream）的服务。 UDP协议（User Datagram Protocol，用户数据报协议）则与TCP协议完全相反，它为应用层提供不可靠、无连接和基于数据报的服务。 网络层 IP协议：IP协议根据数据包的目的IP地址来决定如何投递它，使用逐跳（hop by hop）的方式确定通信路径。（1） 寻址。（2） 路由选择。（3） 分段与组装。 ICMP协议：是IP协议的重要补充，主要用于检测网络连接。(ping工作协议) 数据链路层 ARP协议：ARP地址解析协议用于将计算机的网络地址（IP地址32位）转化为物理地址（MAC地址48位） 原理：主机向自己所在的网络广播一个ARP请求，该请求包含目标机器的网络地址。此网络上的其他机器都将收到这个请求，但只有被请求的目标机器会回应一个ARP应答，其中包含自己的物理地址。ARP维护一个高速缓存，其中包含经常访问（比如网关地址）或最近访问的机器的IP地址到物理地址的映射。这样就避免了重复的ARP请求，提高了发送数据包的速度。 RARP协议：RARP协议（Reverse ARP，反向ARP协议），其功能是将MAC地址解析为对应的IP地址。 TCP UDP UDP头部结构 源端口：16位表示取值范围是1-65535。 目的端口：也是16位。 长度：长度是16位表示，指udp数据包的整体长度，udp数据包最小是8个字节，所以它能发送的最大负载长度是65535-8。 校验和：udp的校验和用16位表示，是检验协议头和负载数据。 TCP头部结构 32位序号（sequence number）：一次TCP通信（从TCP连接建立到断开）过程中某一个传输方向上的字节流的每个字节的编号。序号值被系统初始化为某个随机值ISN（Initial Sequence Number，初始序号值）。 32位确认号（acknowledgement number）：用作对另一方发送来的TCP报文段的响应。其值是收到的TCP报文段的序号值加1。 4位头部长度（header length）：标识该TCP头部有多少个32bit字（4字节）。 标识位： URG标志，表示紧急指针（urgent pointer）是否有效。 ACK标志，表示确认号是否有效。称携带ACK标志的TCP报文段为确认报文段。 PSH标志，提示接收端应用程序应该立即从TCP接收缓冲区中读走数据，为接收后续数据腾出空间。 RST标志，表示要求对方重新建立连接。称携带RST标志的TCP报文段为复位报文段。 SYN标志，表示请求建立一个连接。称携带SYN标志的TCP报文段为同步报文段。 FIN标志，表示通知对方本端要关闭连接了。称携带FIN标志的TCP报文段为结束报文段。 16位窗口大小（window size）：是TCP流量控制的一个手段。这里说的窗口，指的是接收通告窗口（Receiver Window，RWND）。 16位校验和（TCP checksum）：由发送端填充，接收端对TCP报文段执行CRC算法以检验TCP报文段在传输过程中是否损坏。 16位紧急指针（urgent pointer）：是一个正的偏移量。它和序号字段的值相加表示最后一个紧急数据的下一字节的序号。 RST 产生复位报文段的3种情况: 访问不存在的端口 异常终止连接 处理半打开连接 TCP与UDP区别？ （1）连接： TCP 是面向连接的传输层协议，即传输数据之前必须先建立好连接。 UDP是无连接的。 （2）服务对象： TCP 是点对点的两点间服务，即一条 TCP 连接只能有两个端点; UDP 支持一对一，一对多，多对一，多对多的交互通信。 （3）可靠性： TCP 是可靠交付:无差错，不丢失，不重复，按序到达。 UDP 是尽最大努力交付，不保证可靠交付。 （4）拥塞控制，流量控制： TCP 有拥塞控制和流量控制保证数据传输的安全性。 UDP 没有拥塞控制，网络拥塞不会影响源主机的发送效率。 （5) 报文长度： TCP 是动态报文长度，即 TCP 报文长度是根据接收方的窗口大小和当前网络拥塞情况决定的。 UDP 面向报文，不合并，不拆分，保留上面传下来报文的边界。 （6）首部开销： TCP 首部开销大，首部 20 个字节。 UDP 首部开销小，8 字节。(源端口，目的端口，数据长度，校验和) （7）TCP传输速度比UDP慢，TCP是重量级协议、UDP是轻量级协议 TCP建立（三次握手） Client将标志位SYN置为1，随机产生一个值seq=J，并将该数据包发送给Server，等待Server确认。此时客户端进入SYN-SENT（同步已发送） 状态。 SYN报文段（即SYN=1的报文段）不能携带数据，但要消耗一个序号 Server收到数据包后由标志位SYN=1知道Client请求建立连接，Server将标志位SYN和ACK都置1，ack=J+1，随机产生一个值seq=K，并将该数据包发给Client以确认连接请求。这时TCP服务器进行进入SYN-RCVD（同步收到）状态。 同理，此报文段也不能携带数据。 Client收到确认后，检测ack是否为J+1，ACK是否为1，如果正确则将标志位ACK置为1，ack=K+1，并将该数据包发送给Server。完成三次握手，客户端进入ESTABLISHED（已建立连接）状态。当服务器收到客户端的确认后，也进入ESTABLISHED（已建立连接）状态。 TCP标准规定，ACK报文段可以携带数据，但如果不携带数据则不消耗序号 ISN(Initial Sequence Number)初始序号是动态生成的。 TCP关闭（四次挥手） 客户端向服务器发送一个FIN报文，首部的FIN=1，同时报文给自己指定一个序号（m），此时客户端进入FIN_WAIT_1 （终止等待1）状态，但客户端依然可以接收服务器发送来的数据。 TCP规定，FIN报文段即使不携带数据，也要消耗一个序号。 服务端收到了客户端的FIN报文，会发送ACK报文进行确认，把收到报文的序列号的值+1（m+1）作为ACK报文的序列号的值，表明已经收到了客户端的报文，服务器进入CLOSE-WAIT（关闭等待）状态 TCP服务器进程这时应通知高层应用程序，客户端到服务端这个方向的连接就释放了，此时TCP连接处于半关闭（HALF-CLOSE）状态，即客户端已经没有数据要发送了，但服务器若发送数据，客户端仍要接收。客户端收到服务端的确认后，进入FIN-WAIT-2（终止等待2）状态。等待服务端发出的连接释放报文段。 当服务器没有数据要发送了，也想要断开连接，会给客户端发送FIN报文，且指定一个序列号（n），服务器进入了LAST-ACK（最后确认）状态。 客户端收到FIN之后，一样会发送一个ACK报文作为应答，且把服务端的序号+1（n+1）作为自己ACK报文的序号。然后进入TIME-WAIT（时间等待）状态，等待2MSL（MSL：报文段最大生存时间），然后关闭连接。 两次握手不可以： TCP 是全双工通信，两次握手只能确定单向数据链路是可以通信的，并不能保证反向的通信正常 详细解释： 这个问题的本质是：在信道不可靠的情况下, 通信双发需要就某个问题达成一致. 需要几次通信？ 对于此问题，无论在消息中包含什么信息, 三次通信是理论上的最小值. 所以三次握手不是TCP本身的要求, 而是为了满足\"在不可靠信道上可靠地传输信息\"这一需求所导致的 具体来说： TCP连接的双方要确保各自的收发消息的能力都是正常的。 客户端第一次发送握手消息到服务端，服务端接收到握手消息后把ack和自己的syn一同发送给客户端，这是第二次握手，当客户端接收到服务端发送来的第二次握手消息后，客户端可以确认“服务端的收发能力OK，客户端的收发能力OK”，但是服务端只能确认“客户端的发送OK，服务端的接收OK”， 所以还需要第三次握手，客户端收到服务端的第二次握手消息后，发起第三次握手消息，服务端收到客户端发送的第三次握手消息后，就能够确定“服务端的发送OK，客户端的接收OK”， 至此，客户端和服务端都能够确认自己和对方的收发能力OK，TCP连接建立完成。 四次挥手的原因? 因为当处于LISTEN状态的服务器端收到来自客户端的SYN报文(客户端希望新建一个TCP连接)时，它可以把ACK(确认应答)和SYN(同步序号)放在同一个报文里来发送给客户端。但在关闭TCP连接时，当收到对方的FIN报文时，对方仅仅表示对方已经没有数据发送给你了，但是自身可能还有数据需要发送给对方，则等你发送完剩余的数据给对方之后，再发送FIN报文给对方来表示你数据已经发送完毕，并请求关闭连接，所以通常情况下，这里的ACK报文和FIN报文都是分开发送的。 TIME_WAIT的作用 2MSL（MaximumSegment Life，报文段最大生存时间） 保证最后一次握手报文能到服务器，能进行超时重传。 2MSL 后，这次连接的所有报文都会消失，不会影响下一次连接。 缺点： 第一是内存资源占用，但不是很严重，基本可以忽略。 第二是对端口资源的占用，一个 TCP 连接至少消耗一个本地端口。端口资源也是有限的，一般可以开启的端口为 32768～61000 ，也可以通过net.ipv4.ip_local_port_range指定，如果 TIME_WAIT 状态过多，会导致无法创建新连接。 TCP状态转移图 TCP的可靠机制 TCP超时重传 TCP可靠性中最重要的一个机制是处理数据超时和重传。TCP协议要求在发送端每发送一个报文段，就启动一个定时器并等待确认信息；接收端成功接收新数据后返回确认信息。若在定时器超时前数据未能被确认，TCP就认为报文段中的数据已丢失或损坏，需要对报文段中的数据重新组织和重传。 拥塞控制 包含四个部分慢启动（slow start）、拥塞避免（congestion avoidance）、快速重传（fast retransmit）和快速恢复（fast recovery）。 SWND（Send Window，发送窗口 ）、SMSS（Sender Maximum SegmentSize，发送者最大段大小）、接收通告窗口（RWND）、拥塞窗口（CongestionWindow，CWND） 慢启动：CWND将按照指数形式扩大。慢启动算法的理由是，TCP模块刚开始发送数据时并不知道网络的实际情况，需要用一种试探的方式平滑地增加CWND的大小。（cwnd *2） 拥塞避免：慢启动门限（slow start threshold size，ssthresh）。当CWND的大小超过该值时（一般设为65536），TCP拥塞控制将进入拥塞避免阶段，拥塞窗口的值不再指数上升，而是加法增加。（cwnd +1） 快速恢复：当发送方知道只是丢失了个别的报文段，不会启动慢开始算法，而是执行快恢复算法。将阈值设为当前窗口大小的一半，同时设置拥塞窗口为阈值的大小，然后执行拥塞避免算法。 快速重传：发送方只要一连收到3个重复确认，就知道接收方没有收到应当立即进行快重传，这样就不会出现超时。 如何判断拥塞？ 传输超时，或者说TCP重传定时器溢出。采用慢启动和拥塞避免 接收到重复的确认报文段。采用快速重传和快速恢复 TCP 粘包/拆包 怎么解决？ 一个完整的数据包可能会被TCP拆分成多个包进行发送，也有可能把多个小的包封装成一个大的数据包发送，这个就是TCP的拆包和粘包问题。 原因 1、应用程序写入数据的字节大小大于套接字发送缓冲区的大小. 2、进行MSS大小的TCP分段。( MSS=TCP报文段长度-TCP首部长度) 3、以太网的payload大于MTU进行IP分片。（ MTU指：一种通信协议的某一层上面所能通过的最大数据包大小。） 怎么解决 1、消息定长 2、在包尾部增加回车或者空格符等特殊字符进行分割 3、将消息分为消息头和消息尾，在头部中保存有当前整个消息的长度，只有在读取到足够长度的消息之后才算是读到了一个完整的消息 4、使用其它复杂的协议，如RTMP协议等 为什么UDP不粘包？ 对于UDP，不会使用块的合并优化算法，不存在封包，再加上UDP本身是一个“数据包“协议，也就是两段数据是有界限的（保护消息边界：指传输协议把数据当做一条独立的消息在网上传输，接收端一次只能接受一条独立的消息）。从TCP和UDP的头部结构体就可以很明显的看到，UDP头部是记录了数据的长度的，而TCP头部里面并没有记录数据长度的变量。 HTTP HTTP 协议是 Hyper Text Transfer Protocol(超文本传输协议)的缩写，是用于从万维网(WWW:World Wide Web)服务器传输超文本到本地浏览器的传送协议。 HTTP协议采用了请求/响应模型。客户端向服务器发送一个请求报文，请求报文包含请求行(请求的方法、URL、协议版本)、请求头部和请求数据。服务器以一个状态行作为响应，响应的内容包括状态行(协议的版本、成功或者错误代码、服务器信息)、响应头部和响应数据。 在浏览器输入URL地址到显示主页的过程(HTTP请求过程)？ 大概过程： （1）浏览器向DNS 服务器请求解析该URL 中的域名所对应的IP 地址； （2）解析出IP 地址后，根据该IP 地址和默认端口80，和服务器建立TCP 连接； （3）浏览器发出读取文件（URL 中域名后面部分对应的文件）的HTTP 请求，该请求报文作为TCP 三次握手的第三个报文的数据发送给服务器； （4）服务器对浏览器请求作出响应，并把对应的html 文本发送给浏览器； （5）释放TCP 连接； （6）浏览器将该html 文本解析后显示网页内容； 细致过程（笔试原题，排序）： 1、浏览器输入URL，先解析URL地址是否合法 2、浏览器检查是否有缓存（浏览器缓存 - 系统缓存 - 路由器缓存）。如果有，直接显示。没有，进行（3） 3、在发送HTTP请求前，需要域名解析（DNS解析），解析获取对应的IP地址 4、浏览器向服务器发起TCP连接，进行TCP连接的三次握手 5、握手成功后，浏览器向服务器发送HTTP请求，请求数据包 6、服务器收到请求，进行处理后将数据发送给浏览器 7、浏览器收到HTTP响应 8、浏览器解析响应，如果响应可以缓存则存入缓存 9、浏览器发送请求获取嵌入在HTML的资源（HTML、CSS、JS等），对于未知类型，会弹出对话框 10、浏览器发送异步请求 11、页面全部渲染结束显示网页 HTTP请求方法 GET和POST的区别？ GET 和POST 本质上就是TCP 连接，并无差别。但是由于HTTP 的规定和浏览器/服务器的限制，导致他们在应用过程中体现出一些不同。 get 参数通过 url 传递，post 放在 request body 中。 get 请求在 url 中传递的参数是有长度限制的，而 post 没有。 get 请求只能进行 url 编码，而 post 支持多种编码方式。 get 请求会浏览器主动 cache，而 post 支持多种编码方式。 get 请求参数会被完整保留在浏览历史记录里，而post 中的参数不会被保留。 GET 产生一个TCP 数据包；POST 产生两个TCP 数据包。 对于GET 方式的请求，浏览器会把http header 和data 一并发送出去，服务器响应200（返回数据） 对于POST，浏览器先发送header，服务器响应100 continue，浏览器再发送data，服务器响应200 ok（返回数据） HTTP状态码 HTTP的无连接是什么意思？ 无连接的含义是限制每次连接只处理一个请求。服务器处理完客户的请求，并收到客户的应答后，即断开连接。采用这种方式可以节省传输时间。 HTTP的无状态是什么意思？ 无状态是指协议对于事务处理没有记忆能力，服务器不知道客户端是什么状态。即我们给服务器发送 HTTP 请求之后，服务器根据请求，会给我们发送数据过来，但是，发送完，不会记录任何信息。 说一说 HTTP1.0、HTTP1.1、HTTP2.0的区别？ HTTP1.0 HTTP1.0规定浏览器与服务器只保持短暂的连接，浏览器的每次请求都需要与服务器建立一个TCP连接，服务器完成请求处理后立即断开TCP连接。就像打电话一样，一次只能说一件事，说完就要挂断，又因为TCP连接建立一次需要三次握手，所以效率很低。 如果不想断开连接，需要在HTTP相应的Connection字段指定为keep-live connection:keep-alive; HTTP1.1 HTTP1.1引进了持久连接，TCP连接默认不关闭，可以被多个请求复用。客户端和服务端发现对方一段时间没有活动后，可以主动关闭连接；或者客户端在最后一个请求时，主动告诉服务端要关闭连接。 HTTP1.0就像打一次电话只能说一次事，HTTP1.1是打完电话先不直接挂断，而是持续一会，这期间如果有事情还可以再次沟通。 HTTP1.1还引入了管道机制，即在同一个TCP连接里，客户端可以同时发送多个请求，这样就进一步改进了HTTP协议的效率。 HTTP2.0 HTTP2.0采用了多路复用，即在一个连接里，客户端和浏览器都可以同时发送多个请求或回应，而且不用按顺序一一对应。能这样做有一个前提，就是HTTP2.0进行了二进制分帧，即会将所有传输的信息分割为更小的消息和帧，并对它们采用二进制格式的编码。 负责这个拆分、组装请求和二进制帧的一层就叫做二进制分帧层 也就是说，老板可以同时下达多个命令，员工也可以收到请求A和请求B，于是先回应A，结果发现处理A非常耗时，于是就发送A请求已经处理好的部分，接着回应B请求，完成后 ，再发送A请求剩下的部分。A请求的两部分响应再组合到一起发送给老板 除此之外还有一些其他的优化，比如Header压缩、服务端推送等 Header压缩就是压缩老板和员工之间的对话 服务端推送就是员工事先把一些老板可能询问的事情提前发送到老板的手机上（缓存）。这样老板想要知道的时候就可以直接读取短信（缓存）了。 HTTP 和 HTTPS 的区别？ HTTPS （全称：Hyper Text Transfer Protocol over SecureSocket Layer）：是以安全为目标的HTTP通道，简单讲是HTTP的安全版，即HTTP下+SSL，HTTPS的安全基础是SSL，因此加密的详细内容就需要SSL。 HTTPS 采用混合的加密机制，使用非对称密钥加密用于传输对称密钥来保证传输过程的安全性，之后使用对称密钥加密进行通信来保证通信过程的效率。 开销：HTTPS协议需要到CA申请证书，一般免费证书较少，因而需要一定费用。 端口不同：HTTP和HTTPS使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。 安全性：HTTP的连接很简单，是无状态的；HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，比HTTP协议安全。 资源消耗：HTTP是超文本传输协议，信息是明文传输；HTTPS则是具有安全性的SSL加密传输协议，需要消耗更多的CPU和内存资源 在OSI模型中，HTTP工作于应用层，而HTTPS工作于传输层； HTTPS 优点： HTTPS 传输数据过程中使用密钥进行加密，所以安全性更高 HTTPS 协议可以认证用户和服务器，确保数据发送到正确的用户和服务器 HTTPS 缺点： HTTPS 握手阶段延时较高：由于在进行HTTP 会话之前还需要进行SSL 握手，因此HTTPS 协议握手阶段延时增加 HTTPS 部署成本高：一方面HTTPS 协议需要使用证书来验证自身的安全性，所以需要购买CA证书；另一方面由于采用HTTPS 协议需要进行加解密的计算，占用CPU 资源较多。 ps：对称加密中，双方使用公钥进行解密。虽然数字签名可以保证数据不被替换，但数据是由公钥加密的，如果公钥也被替换，则仍然可以伪造数据，因为用户不知道对方提供的公钥是真是假。为了保证发送方的公钥是真的，CA证书机构会负责颁发一个证书，里面的公钥确保是真的，用户请求服务器时，服务器将证书给用户，这个证书是经由系统内置证书的备案过的。 HTTPS的通信建立过程？ 在使用HTTPS是需要保证服务端配置正确了对应的安全证书 客户端发送请求到服务端 服务端返回公钥和数字证书到客户端 客户端接收后会验证证书的安全性，如果通过，则会随机生成一个随机秘钥，用公钥对其加密，发送到服务端 服务端接受到这个加密后的随机秘钥后，会用私钥对其解密，随后用这个随机秘钥当做对称加密密钥对需要发送的数据进行对称加密 客户端在接收到加密后的数据对称加密密钥与服务器通信。 SSL加密建立 什么是数字签名？ 为了避免数据在传输过程中被替换，比如黑客修改了报文内容，但是用户并不知道，所以需要让发送端做一个数字签名，把数据的摘要信息进行一个加密，比如MD5，得到一个签名，和数据一起发送。然后接收端把数据摘要进行MD5加密，如果和签名一样，则说明数据是正确的 什么是数字证书？ 对称加密中，双方使用公钥进行解密。虽然数字签名可以保证数据不被替换，但数据是由公钥加密的，如果公钥也被替换，则仍然可以伪造数据，因为用户不知道对方提供的公钥是真是假。为了保证发送方的公钥是真的，CA证书机构会负责颁发一个证书，里面的公钥确保是真的，用户请求服务器时，服务器将证书给用户，这个证书是经由系统内置证书的备案过的。 Session和cookie的区别？ Cookie是服务器发送到用户浏览器并保存在本地的一小块数据，它会在浏览器之后向同一服务器再次发起请求时被携带上，用于告知服务端两个请求是否来自同一浏览器。由于之后每次请求都会需要携带 Cookie 数据，因此会带来额外的性能开销（尤其是在移动环境下）。 Cookie的工作原理 （1）浏览器端第一次发送请求到服务器端 （2）服务器端创建Cookie，该Cookie中包含用户的信息，然后将该Cookie发送到浏览器端 （3）浏览器端再次访问服务器端时会携带服务器端创建的Cookie （4）服务器端通过Cookie中携带的数据区分不同的用户 Cookie用途 会话状态管理（如用户登录状态、购物车、游戏分数或其它需要记录的信息） 个性化设置（如用户自定义设置、主题等） 浏览器行为跟踪（如跟踪分析用户行为等） Session的工作原理 （1）浏览器端第一次发送请求到服务器端，服务器端创建一个Session，同时会创建一个特殊的Cookie（name为JSESSIONID的固定值，value为session对象的ID），然后将该Cookie发送至浏览器端 （2）浏览器端发送第N（N>1）次请求到服务器端,浏览器端访问服务器端时就会携带该name为JSESSIONID的Cookie对象 （3）服务器端根据name为JSESSIONID的Cookie的value(sessionId),去查询Session对象，从而区分不同用户。 区别： 1、数据存放位置不同：cookie数据存放在客户的浏览器上，session数据放在服务器上。 2、安全程度不同：cookie不是很安全，别人可以分析存放在本地的COOKIE并进行COOKIE欺骗,考虑到安全应当使用session。 3、性能使用程度不同：session会在一定时间内保存在服务器上。当访问增多，会比较占用你服务器的性能,考虑到减轻服务器性能方面，应当使用cookie。 4、数据存储大小不同：单个cookie保存的数据不能超过4K，很多浏览器都限制一个站点最多保存20个cookie，而session则存储与服务端，浏览器对其没有限制。 5、会话机制不同 session会话机制：session会话机制是一种服务器端机制，它使用类似于哈希表（可能还有哈希表）的结构来保存信息。 cookies会话机制：cookie是服务器存储在本地计算机上的小块文本，并随每个请求发送到同一服务器。 Web服务器使用HTTP标头将cookie发送到客户端。在客户端终端，浏览器解析cookie并将其保存为本地文件，该文件自动将来自同一服务器的任何请求绑定到这些cookie。 什么是SQL 注⼊? 举个例子 SQL注⼊就是通过把SQL命令插入到Web表单提交或输入域名或⻚面请求的查询字符串，最终达到欺骗服务器执行恶意的SQL命令。 SQL注⼊攻击的总体思路 寻找到SQL注⼊的位置 判断服务器类型和后台数据库类型 针对不同的服务器和数据库特点进行SQL注入攻击 例子： user: ‘or1=1-- pwd: String sql = “select * from user_table where username=’ “+userName+” ’ and password=’“+password+” ‘”; SELECT * FROM user_table WHERE username=’’or 1 = 1 –- and password=’’ 应对方法 参数绑定 使⽤用正则表达式过滤传⼊入的参数 MTU和MSS分别是什么？ MTU：maximum transmission unit，最大传输单元，由硬件规定，如以太网的MTU为1500字节。 MSS：maximum segment size，最大分节大小，为TCP数据包每次传输的最大数据分段大小，一般由发送端向对端TCP通知对端在每个分节中能发送的最大TCP数据。MSS值为MTU值减去IPv4 Header（20 Byte）和TCP header（20 Byte）得到。 DDos 攻击？ 客户端向服务端发送请求链接数据包，服务端向客户端发送确认数据包，客户端不向服务端发送确认数据包，服务器一直等待来自客户端的确认 没有彻底根治的办法，除非不使用TCP DDos 预防： 1）限制同时打开SYN半链接的数目 2）缩短SYN半链接的Time out 时间 3）关闭不必要的服务 Copyright © YZJ 2022 all right reserved，powered by Gitbook更新时间： 2023-08-13 14:53:06 "},"操作系统.html":{"url":"操作系统.html","title":"操作系统","keywords":"","body":"操作系统 进程、线程、协程 进程 线程 协程 定义 系统进行资源调度和分配的基本单位 CPU调度和分派的基本单位 用户态的轻量级线程，线程内部调度的基本单位 切换情况 进程CPU环境(栈、寄存器、页表和文件句柄等)的保存以及新调度的进程CPU环境的设置 保存和设置程序计数器、少量寄存器和栈的内容 先将寄存器上下文和栈保存，等切换回来的时候再进行恢复 切换者 操作系统 操作系统 用户 切换过程 用户态->内核态->用户态 用户态->内核态->用户态 用户态(没有陷入内核) 调用栈 内核栈 内核栈 用户栈 拥有资源 CPU资源、内存资源、文件资源和句柄等 程序计数器、寄存器、栈和状态字 拥有自己的寄存器上下文和栈 并发性 不同进程之间切换实现并发，各自占有CPU实现并行 一个进程内部的多个线程并发执行 同一时间只能执行一个协程，而其他协程处于休眠状态，适合对任务进行分时处理 系统开销 切换虚拟地址空间，切换内核栈和硬件上下文，CPU高速缓存失效、页表切换，开销很大 切换时只需保存和设置少量寄存器内容，因此开销很小 直接操作栈则基本没有内核切换的开销，可以不加锁的访问全局变量，所以上下文的切换非常快 通信方面 进程间通信需要借助操作系统 线程间可以直接读写进程数据段(如全局变量)来进行通信 共享内存、消息队列 进程与线程的区别？ 答案一： 单位：进程是资源分配的最小单位，线程是CPU调度的最小单位。两者均可并发执行。 从属：一个线程只能属于一个进程，而一个进程可以有多个线程，但至少有一个线程。线程依赖于进程而存在。 资源：进程之间的资源是独立的，进程在执行过程中拥有独立的内存单元，而多个线程共享进程的内存。 资源分配给进程，同一进程的所有线程共享该进程的所有资源。 同一进程中的多个线程共享代码段（代码和常量），数据段（全局变量和静态变量），扩展段（堆存储）。但是每个线程拥有自己的栈段，栈段又叫运行时段，用来存放所有局部变量和临时变量。 系统开销：在创建或撤销进程时，系统都要为之分配或回收资源，系统开销显著大于创建或撤销线程的开销。 在进行进程切换时，设计到整个当前进程CPU环境的保存以及新被调度运行的进程的CPU环境的设置。 而线程切换只需要保存和设置少量寄存器的内容，并不涉及存储管理方面的操作。 切换进程的开销也远大于切换线程的开销。 进程编程调试简单可靠性高，但是创建、销毁、切换开销大；线程正相反，但是编程调试相对复杂 进程之间不会相互影响，一个进程崩溃后，在保护模式下不会对其他进程产生影响，但是一个线程崩溃会导致整个进程崩溃。所以多进程比多线程健壮。 答案二：根本区别就是多进程每个进程有自己的地址空间，线程则是共享地址空间。 速度：线程创建速度快，线程间通信快、切换快，因为它们在同一地址空间内 资源利用率：线程的资源利用率比较好也是因为它们在同一地址空间 同步问题：线程使用公共变量/内存时需要使用同步机制，也是因为它们在同一地址空间内。 协程 是一种比线程更加轻量级的存在。一个线程可以拥有多个协程;协程不是被操作系统内核管理，而完全是由程序所控制。 协程的开销远远小于线程; 协程拥有自己寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切换回来的时候， 恢复先前保存的寄存器上下文和栈。 每个协程表示一个执行单元，有自己的本地数据，与其他协程共享全局数据和其他资源。 跨平台、跨体系架构、无需线程上下文切换的开销、方便切换控制流，简化编程模型; 协程又称为微线程，协程的完成主要靠yeild关键字，协程执行过程中，在子程序内部可中断，然后转而执行别 的子程序，在适当的时候再返回来接着执行; 协程极高的执行效率，和多线程相比，线程数量越多，协程的性能优势就越明显; 不需要多线程的锁机制; 进程的状态转换 进程包括三种状态：就绪、运行、阻塞 就绪 --> 运行：对就绪状态的进程，当进程调度程序按一种选定的策略从中选中一个就绪进程，为之分配处理机后，该进程便由就绪状态变为执行状态 运行 --> 阻塞：正在执行的进程因发生某等待事件而无法运行，则进程由执行状态变为阻塞状态，如进程提出输入/输出请求而变成带带外部设备传入信息的状态；进程申请资源（主存空间或外部设备）得不到满足时编程等待资源状态，进程运行中出现了故障（程序出错或主存储器读写错误等）编程等待干预状态等； 阻塞 --> 就绪：处于阻塞状态的进程，其等待的事件已经发生，如输入/输出完成；资源得到满足；或错误处理完毕时，处于等待状态的进程并不马上转入运行状态，而是先转入就绪状态，再由系统进程调度程序在适当的时候将改进成转为执行状态。 运行 --> 就绪 ：正在执行的进程，因时间片用完而被暂停运行；或在采用抢占式优先级调度算法的系统中，当有更高优先级的进程要运行而被迫让出处理机时，该进程便从运行状态转变为就绪状态 进程调度算法有哪些？ 先来先服务调度算法 有利于长作业，但不利于短作业。 时间片轮转调度算法 因为进程切换都要保存进程的信息并且载入新进程的信息，如果时间片太小，会导致进程切换得太频繁，在进程切换上就会花过多时间。 而如果时间片过长，那么实时性就不能得到保证。 短作业优先调度算法 长作业有可能会饿死，处于一直等待短作业执行完毕的状态。因为如果一直有短作业到来，那么长作业永远得不到调度。 最短剩余时间优先调度算法： 是针对最短进程优先增加了抢占机制的版本 高响应比优先调度算法： 主要用于作业调度，该算法是对先来先服务调度算法和短作业优先调度算法的一种综合平衡，同时考虑每个作业的等待时间和估计的运行时间 优先级调度算法 进程间的通信方式有哪些？ 进程间通信是指在不同的进程之间传递数据或共享资源。由于每个进程都有自己的地址空间，因此进程间通信需要使用特殊的技术来实现，如管道、消息队列、共享内存和套接字等。 管道 管道主要包括普通管道和命名管道：管道可用于具有亲缘关系的父子进程间的通信，有名管道除了具有管道所具有的功能外，它还允许无亲缘关系进程的通信。 普通管道PIPE(无名管道)： 半双工（数据只能在一个方向上流动），具有固定的读端和写端 只能用于具有亲缘关系的进程间通信（也就是父子进程或兄弟进程之间） 它可以看成是一种特殊的文件，对于它的读写也可以使用普通的read、write等函数。但是它不是普通的文件，不属于其他任何文件系统，并且只存在于内存中。 int pipe(int fd[2]); 当一个管道建立时，会创建两个文件文件描述符，要关闭管道只需将这两个文件描述符关闭即可。 命名管道FIFO： 可以在无关的进程之间交换数据 有路径名与之相关联，以一种特殊设备文件形式存在于文件系统中 int mkfifo(const char* pathname,mode_t mode); 消息队列 消息队列是消息的链表，存放在内核中。一个消息队列由一个标识符来标识（即队列ID）。 消息队列是面向记录的，其中的消息具有特定的格式以及特定的优先级； 消息队列独立于发送与接收进程。进程终止时，消息队列及其内容并不会被删除； 消息队列可以实现消息的随机查询。 信号量 信号量是一个计数器，信号量用于实现进程间的互斥与同步，而不是用于存储进程间通信数据； 信号量用于进程间同步，若要在进程间传递数据需要结合共享内存； 信号量基于操作系统的PV操作，程序对信号量的操作都是原子操作； 每次对信号量的PV操作不仅限于对信号量值+1或-1而是可以加减任意正整数； 支持信号量组。 共享内存 共享内存指两个或多个进程共享一块指定的存储区，不同进程可以即时看到对方进程中对共享内存中数据的更新； 因为多个进程可以同时操作，所以需要进行同步； 信号量和共享内存通常结合在一起使用，信号量用来同步对共享内存的访问； 共享内存是最快的一种进程通信方式，因为进程是直接对内存进行存取。 套接字 SOCKET socket也是一种进程间通信机制，用于不同主机之间的进程通信。 线程的通信方式有哪些？ 线程间通信是指在同一个进程内的不同线程之间传递数据或共享资源。由于所有线程都共享同一个地址空间，因此线程间通信比进程间通信更容易实现。常用的线程间通信方式包括互斥锁、条件变量和信号量等。 （1）临界区： 通过多线程的串行化来访问公共资源或一段代码，速度快，适合控制数据访问； （2）信号量： 信号量是一种特殊的变量，可用于线程同步。它只取自然数值，并且只支持两种操作： P(V)：如果信号量大于 0 ，执行 -1 操作；若S减1后仍大于或等于0，则进程继续执行；若S减1后小于0，则该进程被阻塞后放入等待该信号量的等待队列中，然后转进程调度。 V(V)：V+1；若结果大于0，则进程继续执行；若相加后结果仍小于或等于0，则从该信号的等待队列中释放一个等待进程，然后再返回原进程继续执行或转进程调度。 其系统调用为： sem_wait（sem_t *sem）：以原子操作的方式将信号量-1，如果信号量值小于0，则sem_wait将被阻塞，直到这个信号量具有非0 值。 sem_post（sem_t *sem)：以原子操作将信号量值+1。当信号量大于0时，其他正在调用sem_wait等待信号量的线程将被唤醒。 （3）互斥锁： 互斥锁主要用于线程互斥，不能保证按序访问，可以和条件锁一起实现同步。当进入临界区时，需要获得互斥锁并且加锁；当离开临界区时，需要对互斥锁解锁，以唤醒其他等待该互斥锁的线程。其主要的系统调用如下： pthread_mutex_init: 初始化互斥锁 pthread_mutex_destroy：销毁互斥锁 pthread_mutex_lock：以原子操作的方式给一个互斥锁加锁，如果目标互斥锁已经被上锁，pthread_mutex_lock 调用将阻塞，直到该互斥锁的占有者将其解锁。 pthread_mutex_unlock: 以一个原子操作的方式给一个互斥锁解锁。 （4）事件(信号)，Wait/Notify： 通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操作 （5）条件变量： 条件变量，又称条件锁，用于在线程之间同步共享数据的值。条件变量提供一种线程间通信机制：当某个共享数据达到某个值时，唤醒等待这个共享数据的一个/多个线程。即，当某个共享变量等于某个值时，调用signal/broadcast。此时操作共享变量时需要加锁。其主要的系统调用如下： pthread_cond_init: 初始化条件变量 pthread_cond_destroy：销毁条件变量 pthread_cond_signal：唤醒一个等待目标条件变量的线程。哪个线程被唤醒取决于调度策略和优先级。 pthread_cond_wait：等待目标条件变量。需要一个加锁的互斥锁确保操作的原子性。该函数中在进入wait状态前首先进行解锁，然后接收到信号后会再加锁，保证该线程对共享资源正确访问。 守护进程、孤儿进程、僵尸进程 守护进程 指在后台运行的，没有控制终端与之相连的进程。它独立于控制终端，周期性地执行某种任务。Linux的大多数服务器就是用守护进程的方式实现的，如Web服务器进程HTTP等。 孤儿进程 是指一个父进程退出后，而它的一个或多个子进程还在运行，那么这些子进程将成为孤儿进程。孤儿进程将被init进程（进程号为1 是内核启动的第一个用户级进程）所收养，并且由init进程对它们完成状态收集工作。 僵尸进程 是指一个进程使用fork函数创建子进程，如果子进程退出，而父进程并没有调用wait()或者waitpid()系统调用取得子进程的终止状态，那么子进程的进程描述符仍然保存在系统中，占用系统资源，这种进程称为僵尸进程。 区别是：孤儿进程是父进程已退出，子进程未退出；而僵尸进程是父进程未退出，子进程已退出。 如何解决僵尸进程？ （1）一般为了防止产生僵尸进程，在fork子进程之后我们都要及时使用wait系统调用；同时，当子进程退出的时候，内核都会给父进程一个SIGCHLD信号，所以我们可以建立一个捕获SIGCHLD信号的信号处理函数，在函数体中调用wait（或waitpid），就可以清理退出的子进程以达到防止僵尸进程的目的。 （2）使用kill命令。 打开终端并输入下面命令: ps aux | grep Z 会列出进程表中所有僵尸进程的详细内容。 然后输入命令： kill -s SIGCHLD pid(父进程pid) 这样子进程退出后，父进程就会收到信号了。 或者可以强制杀死父进程： kill -9 pid(父进程pid) 这样父进程退出后，这些子进程将成为孤儿进程。孤儿进程将被init进程（进程号为1）所收养，并且由init进程对它们完成状态收集工作。 内存管理 置换算法有哪些？ 当访问一个内存中不存在的页，并且内存已满，则需要从内存中调出一个页或将数据送至磁盘对换区，替换一个页，这种现象叫做缺页置换。当前操作系统最常采用的缺页置换算法如下： 最佳置换(OPT)算法：从主存中移出永远不再需要的页面；如无这样的页面存在，则选择最长时间不需要访问的页面。 先进先出(FIFO)算法：置换最先调入内存的页面，即置换在内存中驻留时间最久的页面。按照进入内存的先后次序排列成队列，从队尾进入，从队首删除。 最近最少使用（LRU）算法: 置换最近一段时间以来最长时间未访问过的页面。根据程序局部性原理，刚被访问的页面，可能马上又要被访问；而较长时间内没有被访问的页面，可能最近不会被访问。 时钟（CLOCK）置换算法：最佳置换算法性OPT能最好，但无法实现；先进先出置换算法实现简单，但算法性能差；最近最久未使用置换算法性能好，是最接近OPT算法性能的，但是实现起来需要专门的硬件支持，算法开销大。 所以操作系统的设计者尝试了很多算法，试图用比较小的开销接近LRU的性能，这类算法都是CLOCK算法的变体，因为算法要循环扫描缓冲区像时钟一样转动。所以叫clock算法。 时钟置换算法是一种性能和开销较均衡的算法，又称CLOCK算法，或最近未用算法(NRU，Not Recently Used) 简单的CLOCK算法实现方法:为每个页面设置一个访问位，再将内存中的页面都通过链接指针链接成一个循环队列。当某页被访问时，其访问位置为1。当需要淘汰-一个页面时，只需检查页的访问位。如果是0，就选择该页换出;如果是1，则将它置为0，暂不换出，继续检查下一个页面，若第- - ~轮扫描中所有页面都是1，则将这些页面的访问位依次置为0后，再进行第二轮扫描(第二轮扫描中一定会有访问位为0的页面，因此简单的CLOCK算法选择–个淘汰页面最多会经过两轮扫描) LRU算法及实现 LRU算法用于缓存淘汰。思路是将缓存中最近最少使用的对象删除。实现方式：利用链表和hashmap。 当需要插入新的数据项的时候，如果新数据项在链表中存在（一般称为命中），则把该节点移到链表头部，如果不存在，则新建一个节点，放到链表头部，若缓存满了，则把链表最后一个节点删除即可。在访问数据的时候，如果数据项在链表中存在，则把该节点移到链表头部，否则返回-1。这样一来在链表尾部的节点就是最近最久未访问的数据项。 #include using namespace std; class LRU { public: LRU(int capacity): cap(capacity){} int get(int key){ if(map.find(key) == map.end()) return -1; auto key_value = *map[key]; // 迭代器解引用 cache.erase(map[key]); cache.push_front(key_value); map[key] = cache.begin(); cout > cache; unordered_map>::iterator> map; }; int main(){ LRU lRUCache = LRU(2); lRUCache.put(1, 1); // 缓存是 {1=1} lRUCache.put(2, 2); // 缓存是 {1=1, 2=2} lRUCache.get(1); // 返回 1 lRUCache.put(3, 3); // 该操作会使得关键字 2 作废，缓存是 {1=1, 3=3} lRUCache.get(2); // 返回 -1 (未找到) lRUCache.put(4, 4); // 该操作会使得关键字 1 作废，缓存是 {4=4, 3=3} lRUCache.get(1); // 返回 -1 (未找到) lRUCache.get(3); // 返回 3 lRUCache.get(4); // 返回 4 } 分页和分段的区别？ 段是信息的逻辑单位，它是根据用户的需要划分的，因此段是对用户可见的；页是信息的物理单位，是为了管理主存的方便而划分的，对用户是透明的； 段的大小不固定，有它所完成的功能决定；页的大小固定，由系统决定 段向用户提供二维地址空间；页向用户提供的是一维地址空间 段是信息的逻辑单位，便于存储保护和信息共享，页的保护和共享收到限制 物理地址、逻辑地址、虚拟内存、物理内存的概念？ 物理地址： 它是地址转换的最终地址，进程在运行时执行指令和访问数据最后都要通过物理地址从主存中存取，是内存单元的真正地址 逻辑地址： 是指用户看到的地址。逻辑地址并不一定是元素存储的真实地址，即数组元素的物理地址（在内存条中的所处的位置）并非是连续的，只是通过操作系统通过地址映射，将逻辑地址映射成连续的，这样使用更符合人们的直观思维 物理内存 寄存器：速度最快、量少、价格贵。 高速缓存：次之。 主存：再次之。 磁盘：速度最慢、量多、价格便宜。 虚拟内存： 虚拟内存是一种内存管理技术，它会使程序自己认为自己拥有一块很大且连续的内存，然而，这个程序在内存中不是连续的，并且有些还会在磁盘上，在需要时进行数据交换。虚拟内存与物理内存存在映射关系，通过页表寻址完成虚拟地址和物理地址的转换。 逻辑地址转物理地址 一句话来说：逻辑地址左移四位加偏移地址就是物理地址 逻辑地址 = 段地址：偏移地址 具体运算：段地址×16（左移四位，也就是2的四次方，相当于乘16）+偏移地址=物理地址（可以理解为段地址末尾补一个零） 逻辑地址是 1000H：0001H 那么物理地址为1000H×16+0001H=10001H 因为地址本身一般都是十六进制数，所以只需要把段地址左移一位末尾补0再和偏移地址加起来就是物理地址 虚拟内存的好处和坏处？ 虚拟内存的好处 扩大地址空间； 内存保护：每个进程运行在各自的虚拟内存地址空间，互相不能干扰对方。虚存还对特定的内存地址提供写保护，可以防止代码或数据被恶意篡改。 公平内存分配。采用了虚存之后，每个进程都相当于有同样大小的虚存空间。 当进程通信时，可采用虚存共享的方式实现。 当不同的进程使用同样的代码时，比如库文件中的代码，物理内存中可以只存储一份这样的代码，不同的进程只需要把自己的虚拟内存映射过去就可以了，节省内 虚拟内存很适合在多道程序设计系统中使用，许多程序的片段同时保存在内存中。当一个程序等待它的一部分读入内存时，可以把CPU 交给另一个进程使用。在内存中可以保留多个进程，系统并发度提高 在程序需要分配连续的内存空间的时候，只需要在虚拟内存空间分配连续空间，而不需要实际物理内存的连续空间，可以利用碎片 虚拟内存的代价： 虚存的管理需要建立很多数据结构，这些数据结构要占用额外的内存 虚拟地址到物理地址的转换，增加了指令的执行时间。 页面的换入换出需要磁盘I/O，这是很耗时的 如果一页中只有一部分数据，会浪费内存。 wait()函数 wait函数是用来及时回收我们的进程资源的。 进程一旦调用了wait函数，就立即阻塞自己本身，然后由wait函数自动分析当前进程的某个子进程是否已经退出，当找到一个已经变成僵尸的子进程，wait就会收集这个子进程的信息，并把它彻底销毁后返回；如果没有找到这样一个子进程，wait就会一直阻塞，直到有一个出现为止。函数原型如下： #include #include pid_t wait(int* status); 子进程的结束状态值会由参数status返回，而子进程的进程识别码也会一起返回。如果不需要结束状态值，则参数status可以设成 NULL。 fork()函数 fork函数用来创建一个子进程。对于父进程，fork()函数返回新创建的子进程的PID。对于子进程，fork()函数调用成功会返回0。如果创建出错，fork()函数返回-1。 #include pid_t fork(void); fork()函数不需要参数，返回值是一个进程标识符PID。返回值有以下三种情况： （1） 对于父进程，fork()函数返回新创建的子进程的PID。 （2） 对于子进程，fork()函数调用成功会返回0。 （3） 如果创建出错，fork()函数返回-1。 fork()函数创建一个新进程后，会为这个新进程分配进程空间，将父进程的进程空间中的内容复制到子进程的进程空间中，包括父进程的数据段和堆栈段，并且和父进程共享代码段。这时候，子进程和父进程一模一样，都接受系统的调度。因为两个进程都停留在fork()函数中，最后fork()函数会返回两次，一次在父进程中返回，一次在子进程中返回，两次返回的值不一样，如上面的三种情况。 其他 什么是并发和并行？ 并发：对于单个CPU，在一个时刻只有一个进程在运行，但是线程的切换时间则减少到纳秒数量级，多个任务不停来回快速切换。 并行：对于多个CPU，多个进程同时运行。 区别：并行的\"同时\"是同一时刻可以多个任务在运行，并发的\"同时\"是经过不同线程快速切换，使得看上去多个任务同时都在运行的现象。 同步与异步、阻塞与非阻塞的区别？ 同步：同步是指一个进程在执行请求需要一段时间才能返回信息，那么这个进程将会一直等待下去，直到收到返回信息才继续执行下去。 异步：异步是指进程不需要一直等下去， 而是继续执行下面的操作，当有消息返回时系统会通知进程进行处理，这样可以提高执行的效率。 阻塞：调用者调用了某个函数，等待这个函数返回，期间什么也不做，不停的检查这个函数有没有返回，必须等这个函数返回后才能进行下一步动作。 非阻塞：非阻塞等待，每隔一段时间就去检查IO事件是否就绪。没有就绪就可以做其他事情。 阻塞和非阻塞是线程的一种状态，同步和异步是指的是线程执行方法的一种方式，当然同步执行时，一般都伴随着线程的阻塞。 内核态与用户态的区别？ 内核态与用户态：内核态（系统态）与用户态是操作系统的两种运行级别。内核态拥有最高权限，可以访问所有系统指令；用户态则只能访问一部分指令。 什么时候进入内核态： 系统调用（Trap） ：用户态进程 主动 要求切换到内核态的一种方式，主要是为了使用内核态才能做的事情比如读取磁盘资源。系统调用的机制其核心还是使用了操作系统为用户特别开放的一个中断来实现。 中断（Interrupt） ：当外围设备完成用户请求的操作后，会向 CPU 发出相应的中断信号，这时 CPU 会暂停执行下一条即将要执行的指令转而去执行与中断信号对应的处理程序，如果先前执行的指令是用户态下的程序，那么这个转换的过程自然也就发生了由用户态到内核态的切换。比如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等。 异常（Exception）：当 CPU 在执行运行在用户态下的程序时，发生了某些事先不可知的异常，这时会触发由当前运行进程切换到处理此异常的内核相关程序中，也就转到了内核态，比如缺页异常。 其中，系统调用是主动的，另外两种是被动的。 为什么区分内核态与用户态： 在CPU的所有指令中，有一些指令是非常危险的，如果错用，将导致整个系统崩溃。比如：清内存、设置时钟等。所以区分内核态与用户态主要是出于安全的考虑。 中断流程？ 中断是指当出现需要时，CPU暂时停止当前进程的执行，转而执行处理新情况的中断处理程序。当执行完该中断处理程序后，则重新从刚才停下的位置继续当前进程的运行。 为了区分不同的中断，每个设备有自己的中断号。系统有0-255一共256个中断。系统有一张中断向量表，用于存放256个中断的中断服务程序入口地址。每个入口地址对应一段代码，即中断服务程序。 什么是系统调用？ 运行的用户程序中，凡是与系统态级别的资源有关的操作（如文件管理、进程控制、内存管理等)，都必须通过系统调用方式向操作系统提出服务请求，系统调用和普通的函数调用非常相似。区别仅仅在于，系统调用由操作系统核心提供，运行于核心态；而普通的函数调用由函数库或用户自己提供，运行于用户态。 系统调用的过程可以简单分为以下几个步骤： 用户态的程序发起系统调用，因为系统调用中涉及一些特权指令（只能由操作系统内核态执行的指令），用户态程序权限不足，因此会中断执行，也就是 Trap（Trap 是一种中断）。 发生中断后，当前 CPU 执行的程序会中断，跳转到中断处理程序。内核程序开始执行，也就是开始处理系统调用。 内核处理完成后，主动触发 Trap，这样会再次发生中断，切换回用户态工作。 外中断和异常有什么区别？ 外中断是指由 CPU 执行指令以外的事件引起，如 I/O 完成中断，表示设备输入/输出处理已经完成，处理器能够发送下一个输入/输出请求。此外还有时钟中断、控制台中断等。 异常时由 CPU 执行指令的内部事件引起，如非法操作码、地址越界、算术溢出等。 抖动是什么？ 刚刚换出的页面马上又要换入内存，刚刚换入的页面马上又要换出外存，这种频繁的页面调度行为称为抖动，或颠簸。产生抖动的主要原因是进程频繁访问的页面数目高于可用的物理块数(分配给进程的物理块不够) 为进程分配的物理块太少，会使进程发生抖动现象。为进程分配的物理块太多，又会降低系统整体的并发度，降低某些资源的利用率 为了研究为应该为每个进程分配多少个物理块，Denning 提出了进程工作集” 的概念 什么是死锁，产生的条件，如何解决、避免？ 由于系统中存在一些不可剥夺资源，当两个或两个以上进程在执行过程中，因争夺资源而造成的相互等待，使每个进程都无法向前推进的现象。 产生的条件：死锁发生有四个必要条件： 互斥条件：进程对所分配到的资源不允许其他进程访问，若其他进程访问该资源，只能等待，直至占有该资源的进程使用完成后释放该资源； 请求和保持条件：进程获得一定的资源后，又对其他资源发出请求，但是该资源可能被其他进程占有，此时请求阻塞，但该进程不会释放自己已经占有的资源； 不可剥夺条件：进程已获得的资源，在未完成使用之前，不可被剥夺，只能在使用后自己释放; 环路等待条件：进程发生死锁后，必然存在一个进程-资源之间的环形链，链中每个进程已获得的资源同时被链中下一个进程所请求。 如何解决： 破坏请求和保持条件： 一次性分配所有资源，这样就不会再有请求了 只要有一个资源得不到分配，就不给这个进程分配其他资源 破坏不可剥夺资源： 当进程新的资源未得到满足时，释放已占有的资源，从而破坏不可剥夺的条件 破坏环路等待条件： 资源有序分配法：系统给每类资源赋予一个序号，每个进程按编号递增的请求资源，释放则相反，从而破坏环路等待的条件 鸵鸟策略：把头埋在沙子里，假装根本没发生问题。忽略死锁。 几种典型锁？ 读写锁 多个读者可以同时进行读 写者必须互斥（只允许一个写者写，也不能读者写者同时进行） 写者优先于读者（一旦有写者，则后续读者必须等待，唤醒时优先考虑写者） 互斥锁 一次只能一个线程拥有互斥锁，其他线程只有等待 互斥锁是在抢锁失败的情况下主动放弃CPU进入睡眠状态直到锁的状态改变时再唤醒，而操作系统负责线程调度，为了实现锁的状态发生改变时唤醒阻塞的线程或者进程，需要把锁交给操作系统管理，所以互斥锁在加锁操作时涉及上下文的切换。互斥锁实际的效率还是可以让人接受的，加锁的时间大概100ns左右，而实际上互斥锁的一种可能的实现是先自旋一段时间，当自旋的时间超过阀值之后再将线程投入睡眠中，因此在并发运算中使用互斥锁（每次占用锁的时间很短）的效果可能不亚于使用自旋锁 条件变量 互斥锁一个明显的缺点是他只有两种状态：锁定和非锁定。而条件变量通过允许线程阻塞和等待另一个线程发送信号的方法弥补了互斥锁的不足，他常和互斥锁一起使用，以免出现竞态条件。当条件不满足时，线程往往解开相应的互斥锁并阻塞线程然后等待条件发生变化。一旦其他的某个线程改变了条件变量，他将通知相应的条件变量唤醒一个或多个正被此条件变量阻塞的线程。总的来说互斥锁是线程间互斥的机制，条件变量则是同步机制。 自旋锁 当一个线程尝试去获取某一把锁的时候，如果这个锁已经被另外一个线程占有了，那么此线程就无法获取这把锁，该线程会等待，间隔一段时间后再次尝试获取。这种采用循环加锁,等待锁释放的机制就称为自旋锁。 五种IO模型 IO（Input/Output，输入/输出）即数据的读取（接收）或写入（发送）操作。通常用户进程中的一个完整IO分为两阶段：用户进程空间与内核空间之间的相互切换、内核空间与设备空间的相互切换（磁盘、网络等）。我们通常说的IO是指网络IO和磁盘IO两种。Linux中进程无法直接操作I/O设备，其必须通过系统调用请求内核来协助完成I/O动作；内核会为每个I/O设备维护一个缓冲区。对于一个输入操作来说，进程IO系统调用后，内核会先看缓冲区中有没有相应的缓存数据，没有的话再到设备中读取，因为设备IO一般速度较慢，需要等待；内核缓冲区有数据则直接复制到进程空间。所以，对于一个网络输入操作通常包括两个不同阶段： 等待网络数据到达网卡→读取到内核缓冲区，数据准备好； 从内核缓冲区复制数据到进程空间。 5种IO模型如下： 阻塞IO：进程发起IO系统调用后，进程被阻塞，转到内核空间处理，整个IO处理完毕后返回进程。操作成功则进程获取到数据。调用者将一直等待，不停的检查这个函数有没有返回，必须等这个函数返回后才能进行下一步动作。 非阻塞IO：进程发起IO系统调用后，进程被阻塞，内核数据还没好，不想让进程等待，就返回一个错误，这样进程就不阻塞了。进程每隔一段时间就发起IO系统调用去检查IO事件是否就绪。这样就实现非阻塞了。每个进程都有一个时间片，轮询的时候读取IO，时间片到了就要换另一个进程做其他事情了，这样就做到了每隔一段时间发起IO系统调用。 IO多路复用：Linux用select/poll函数实现IO复用模型，这两个函数也会使进程阻塞，但是和阻塞IO所不同的是这两个函数可以同时阻塞多个IO操作。而且可以同时对多个读操作、写操作的IO函数进行检查。select/poll会监听所有的IO，直到有数据可读或可写时，才真正调用IO操作函数。 信号驱动IO：Linux用套接口进行信号驱动IO，安装一个信号处理函数，进程继续运行并不阻塞，当IO事件就绪，进程收到SIGIO信号，然后处理IO事件。这个好理解，这个信号直接通知进程数据到了。 异步IO：进程发起IO系统调用后立即返回，当内核将数据拷贝到缓冲区后，再通知应用程序。用户可以直接去使用数据。具体操作是进程调用aio_read函数告诉内核描述字缓冲区指针和缓冲区的大小、文件偏移及通知的方式，然后立即返回。 前四种属于同步IO，原因就在于进程发起IO系统调用读取数据时，这个真正拿到数据的过程依然是阻塞的，直到完成数据读取还要把数据拷贝到用户空间中，进程才能继续做其他事。 而异步IO就不一样了，进程完全做自己的事情，数据都不需要它读取，而是由内核读取数据并将数据拷贝到缓冲区后，再通知应用程序。用户可以直接去使用数据。 I/O 多路复用（ IO multiplexing） IO多路复用就是通过一个进程可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作的一种机制。 I/O多路复用的本质是使用select ，poll 或 epoll函数，挂起进程，当一个或多个IO事件发生之后，将控制返回给用户进程。 以服务器编程为例，传统的多进程（多线程）并发模型，在处理用户连接时都是开启一个新的线程或进程去处理一个新的连接，而IO多路复用则是可以在一个进程（线程）中同时监听多个网络IO事件，也就是多个文件描述符 I/O复用函数本身是阻塞的，能提高程序效率的原因在于它们具有同时监听多个I/O事件的能力。 select int select (int n, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout); 每次调用select，都需要把监听的文件描述符集合 fd_set从用户态拷贝多内核态，从算法角度来说就是$O(N)$的时间开销 每次调用select返回之后都需要遍历所有文件描述符，判断哪些文件描述符有读写事件发生，也是$O(N)$的时间开销 内核对被监控的文件描述符的集合大小做了限制，并且这个是通过宏控制的，大小不可改变，为1024。这一点和上一个缺点是矛盾的，文件描述符设大了，遍历时间就长，其效率也会下降 poll int poll (struct pollfd *fds, unsigned int nfds, int timeout); struct pollfd { int fd; /* file descriptor */ short events; /* requested events to watch */ short revents; /* returned events witnessed */ }; poll和select本质上没有差别，管理多个描述符也是进行轮询，根据描述符的状态进行处理，但是poll没有最大文件描述符数量的限制。 select采用fdset（fdset采用了bitmap），poll采用了数组，所以表示的描述符比select大 poll和select同样存在一个缺点就是，文件描述符的数组被整体复制于用户态和内核态的地址空间之间，而不管这些文件描述符是否有事件，它们的开销随着文件描述符数量的增加而线性增大。 poll返回后，也需要遍历整个描述符的数组才能得到有事件的描述符 epoll int epoll_create(int size)；//创建一个epoll的句柄，size用来告诉内核这个监听的数目一共有多大 int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)； int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout); epoll解决了select和poll在文件描述符集合拷贝和遍历上的问题，能够在一个进程中监听多个文件描述符，并且十分高效 在内核当中epoll是以红黑树的方式组织监听事件的，所以查询开销是O(logn)。采用回调的方式检测就绪事件，时间复杂度是O(1) 在注册监听事件时从用户态将数据传入内核态；当返回时需要将就绪队列的内容拷贝到用户空间 对于select和poll来说，所有文件描述符都是在用户态被加入其文件描述符集合的，每次调用都需要将整个集合拷贝到内核态；epoll则将整个文件描述符集合维护在内核态，每次添加文件描述符的时候都需要执行一个系统调用。系统调用的开销是很大的，而且在有很多短期活跃连接的情况下，epoll可能会慢于select和poll由于这些大量的系统调用开销。 select使用线性表描述文件描述符集合，文件描述符有上限；poll使用链表来描述；epoll底层通过红黑树来描述，并且维护一个ready list，将事件表中已经就绪的事件添加到这里，在使用epoll_wait调用时，仅观察这个list中有没有数据即可。 select和poll的最大开销来自内核判断是否有文件描述符就绪这一过程：每次执行select或poll调用时，它们会采用遍历的方式，遍历整个文件描述符集合去判断各个文件描述符是否有活动；epoll则不需要去以这种方式检查，当有活动产生时，会自动触发epoll回调函数通知epoll文件描述符，然后内核将这些就绪的文件描述符放到之前提到的ready list中等待epoll_wait调用后被处理。 select和poll都只能工作在相对低效的LT模式下，而epoll同时支持LT和ET模式。 综上，当监测的fd数量较小，且各个fd都很活跃的情况下，建议使用select和poll；当监听的fd数量较多，且单位时间仅部分fd活跃的情况下，使用epoll会明显提升性能。 LT（电平触发） 假设委托内核检测读事件 -> 检测fd的读缓冲区 读缓冲区有数据 - > epoll检测到了会给用户通知 a.用户不读数据，数据一直在缓冲区，epoll 会一直通知 b.用户只读了一部分数据，epoll会通知 c.缓冲区的数据读完了，不通知 LT（level - triggered）是缺省的工作方式，并且同时支持 block 和 no-block socket。在这种做法中，内核告诉你一个文件描述符是否就绪了，然后你可以对这个就绪的 fd 进行 IO 操作。如果你不作任何操作，内核还是会继续通知你的。 效率会低于ET触发，尤其在高并发大流量的情况下。但是LT对代码编写要求比较低，不容易出现问题。LT模式服务编写上的表现是：只要有数据没有被获取，内核就不断通知你，因此不用担心时间丢失的情况。 ET（边缘触发） 假设委托内核检测读事件 -> 检测fd的读缓冲区 读缓冲区有数据 - > epoll检测到了会给用户通知 a.用户不读数据，数据一致在缓冲区中，epoll下次检测的时候就不通知了 b.用户只读了一部分数据，epoll不通知 c.缓冲区的数据读完了，不通知 ET（edge - triggered）是高速工作方式，只支持 no-block socket。在这种模式下，当描述符从未就绪变为就绪时，内核通过epoll告诉你。然后它会假设你知道文件描述符已经就绪，并且不会再为那个文件描述符发送更多的就绪通知，直到你做了某些操作导致那个文件描述符不再为就绪状态了。但是请注意，如果一直不对这个 fd 作 IO 操作（从而导致它再次变成未就绪），内核不会发送更多的通知（only once）。ET 模式在很大程度上减少了 epoll 事件被重复触发的次数，因此效率要比 LT 模式高。epoll工作在 ET 模式的时候，必须使用非阻塞套接口，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。 效率非常高，在高并发大流量的情况下，会比LT少很多epoll的系统调用，因此效率高。但是对编程要求高，需要细致的处理每个请求，否则容易发生丢失事件的情况 Copyright © YZJ 2022 all right reserved，powered by Gitbook更新时间： 2023-08-13 15:40:24 "},"GPT.html":{"url":"GPT.html","title":"搭建自己的GPT","keywords":"","body":"搭建GPT 快捷指令 获取免费的GPT3 API 部署教程 https://github.com/Yidadaa/ChatGPT-Next-Web/ 示例：https://gpt.yangzejin.com/ Copyright © YZJ 2022 all right reserved，powered by Gitbook更新时间： 2023-08-13 14:56:15 "}}